# 📚 **الفهرس : الدليل الشامل لمكتبة Pandas**

## الجزء 1: الأساسيات (من الصفر إلى المتوسط)

1. **الدرس 1: تعريف DataFrame وكيفية إنشائه**
   - ما هو DataFrame؟
   - إنشاء DataFrame من قاموس
   - إنشاء DataFrame من قائمة
   - إنشاء DataFrame من مصفوفة NumPy
   - خصائص DataFrame
   - الأخطاء الشائعة عند الإنشاء

2. **الدرس 2: قراءة البيانات من ملفات CSV وExcel وJSON**
   - قراءة ملف CSV باستخدام `read_csv()`
   - قراءة ملف Excel باستخدام `read_excel()`
   - قراءة ملف JSON باستخدام `read_json()`
   - خيارات مهمة: `sep`, `encoding`, `index_col`
   - الأخطاء الشائعة عند القراءة

3. **الدرس 3: فحص معلومات الجدول**
   - `df.info()` – عرض معلومات عامة
   - `df.dtypes` – أنواع البيانات
   - `df.describe()` – الإحصاءات الوصفية
   - `df.isnull()` و`df.notnull()` – اكتشاف القيم المفقودة
   - تمارين تطبيقية على جودة البيانات

4. **الدرس 4: الوصول إلى الأعمدة والصفوف باستخدام `loc` و `iloc`**
   - الفرق بين `loc` و `iloc`
   - الوصول إلى عمود أو صف
   - استخدام `loc` مع شروط
   - أمثلة عملية على الاستخراج

5. **الدرس 5: الفلترة الشرطية**
   - الفلترة باستخدام الشروط البسيطة
   - استخدام `&` (و) و `|` (أو)
   - استخدام `~` (ليس)
   - دوال مساعدة: `isin()` و `between()`
   - الأخطاء الشائعة في الفلترة

6. **الدرس 6: التعديل داخل DataFrame**
   - إنشاء أعمدة جديدة
   - التعديل على القيم
   - حذف أعمدة وصفوف
   - إعادة تسمية الأعمدة باستخدام `rename()`
   - استخدام `inplace=True`

7. **الدرس 7: التعامل مع القيم المفقودة**
   - اكتشاف القيم المفقودة بـ `isnull()`
   - حذف الصفوف/الأعمدة بـ `dropna()`
   - ملء القيم المفقودة بـ `fillna()`
   - استراتيجيات التعامل مع `NaN`
   - تمارين على جودة البيانات

8. **الدرس 8: التجميع باستخدام `groupby()`**
   - التجميع حسب عمود
   - حساب المجموع، المتوسط، العدد
   - استخدام `agg()` لدوال متعددة
   - التجميع حسب أكثر من عمود
   - تطبيقات على المبيعات والموظفين

9. **الدرس 9: ترتيب البيانات باستخدام `sort_values()`**
   - الترتيب التصاعدي والتنازلي
   - الترتيب حسب أكثر من عمود
   - التحكم في القيم المفقودة: `na_position`
   - استخدام `sort_index()`
   - تمارين على ترتيب النتائج

10. **الدرس 10: دمج وربط البيانات باستخدام `merge` و `concat`**
    - الدمج الرأسي باستخدام `concat()`
    - الدمج الأفقي
    - الربط باستخدام `merge()` (مثل JOIN)
    - أنواع الدمج: `inner`, `left`, `outer`, `right`
    - تطبيقات على الطلبات والعملاء

11. **الدرس 11: التعامل مع الأعمدة الزمنية**
    - تحويل النص إلى تاريخ بـ `pd.to_datetime()`
    - استخراج السنة، الشهر، اليوم باستخدام `.dt`
    - تصفية البيانات حسب التواريخ
    - استخدام `between()` مع التواريخ
    - تمارين على المبيعات الزمنية

12. **الدرس 12: حفظ البيانات إلى ملفات**
    - حفظ إلى CSV باستخدام `to_csv()`
    - خيارات مهمة: `index=False`, `encoding='utf-8-sig'`, `mode='a'`
    - حفظ إلى Excel باستخدام `to_excel()`
    - استخدام `ExcelWriter` لأكثر من ورقة
    - حفظ إلى JSON باستخدام `to_json()`
    - الأخطاء الشائعة عند الحفظ

---

## الجزء 2: المستوى المتقدم

13. **الدرس 13: معالجة متعددة المستويات (MultiIndex)**
    - إنشاء `MultiIndex` من `from_tuples` و `from_product`
    - الوصول إلى البيانات باستخدام `loc` و `xs()`
    - استخدام `stack()` و `unstack()`
    - تبديل المستويات بـ `swaplevel()`
    - تطبيقات على تحليل متعدد الأبعاد

14. **الدرس 14: العمليات الإحصائية المتقدمة**
    - النافذة المتحركة: `rolling().mean()`, `std()`
    - التوسع التراكمي: `expanding()`
    - المتوسط المرجح أسيًا: `ewm()`
    - التباين وارتباط بيرسون: `cov()`, `corr()`
    - الرتبة والتقييم: `rank()`, `nlargest()`, `nsmallest`

15. **الدرس 15: Pivot والتحليل العميق**
    - استخدام `pivot()` للبيانات الفريدة
    - استخدام `pivot_table()` مع التكرارات
    - إضافة دالة تجميع: `aggfunc`
    - ملء القيم المفقودة: `fill_value`
    - إضافة الإجماليات: `margins=True`
    - استخدام `crosstab()` لجداول التقابل

16. **الدرس 16: التجهيز للذكاء الاصطناعي (ML)**
    - الترميز الوهمي: `get_dummies()`
    - تقسيم الأرقام: `cut()` و `qcut()`
    - استبدال القيم: `map()` و `replace()`
    - تغيير نوع البيانات: `astype()`
    - تصفية متقدمة: `query()` و `eval()`

17. **الدرس 17: البيانات الزمنية المتقدمة**
    - إعادة عينة البيانات: `resample('D')`, `resample('W')`
    - تغيير التردد: `asfreq()`
    - الإزاحة الزمنية: `shift()` (Lag/Lead)
    - الفرق بين القيم: `diff()`
    - النسبة المئوية: `pct_change()`

18. **الدرس 18: التعامل مع الأخطاء والنسخ الآمن**
    - فهم `SettingWithCopyWarning`
    - الحل: استخدام `.copy()`
    - الفرق بين `deep=True` و `deep=False`
    - تجنب الأخطاء باستخدام `errors='ignore'`
    - كتم التحذيرات (بشكل آمن)

19. **الدرس 19: الوظائف المتقدمة**
    - `apply()` على الصفوف والأعمدة
    - `pipe()` لبناء أنابيب معالجة
    - `transform()` مع `groupby`
    - `filter()` لتصفية الأعمدة بالاسم
    - أمثلة على أنظمة معالجة تلقائية

20. **الدرس 20: مشروع تطبيقي: تحليل بيانات أسهم**
    - توليد بيانات وهمية لسهم
    - حساب المؤشرات الفنية (متوسطات متحركة)
    - تحليل متعدد المستويات
    - إنشاء Pivot Table و crosstab
    - تجهيز البيانات لنموذج ML
    - بناء أنبوب معالجة باستخدام `pipe`

---

## الملحقات

- **جدول مرجعي سريع لأهم دوال Pandas**
- **نصائح احترافية للمبتدئين والمحترفين**
- **تمارين تطبيقية واقعية**
- **أمثلة من عالم المبيعات، التداول، والموارد البشرية**


# 📚  الدليل الكامل: Pandas من الصفر إلى المستوى المتوسط

> ✅ **إجمالي الدروس: 12**  
> ✅ **عدد الكلمات: أكثر من 16,700**

---

## 📘 **الدرس 1: تعريف DataFrame وكيفية إنشائه من قائمة أو قاموس أو NumPy**
- مقدمة: لماذا Pandas؟ ولماذا DataFrame؟
- ما هو DataFrame؟ (شرح نظري مفصل)
  - خصائص الـ DataFrame
  - تشبيه بسيط: السجل المدرسي
- كيفية إنشاء DataFrame؟
  - الطريقة 1: من قاموس (Dict) — الأسهل والأكثر شيوعًا
  - الطريقة 2: من قائمة (List of Lists)
  - الطريقة 3: من مصفوفة NumPy
  - الطريقة 4: من قائمة من القواميس
- فهم نوع البيانات (dtypes) عند الإنشاء
- الأخطاء الشائعة عند الإنشاء (تحليل معمق)
- تمارين تطبيقية (من السهل إلى الصعب)
- الربط بالواقع: مشروع صغير — إدارة متجر
- نصائح احترافية للمبتدئين
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 2: قراءة البيانات من ملفات CSV وExcel وJSON**
- مقدمة: لماذا نقرأ من ملفات؟
- قراءة ملف CSV باستخدام `pd.read_csv()`
  - ما هو ملف CSV؟
  - مثال عملي
- خيارات مهمة في `read_csv`
  - `sep`, `header`, `index_col`, `encoding`, `nrows`, `skiprows`
- قراءة ملف Excel باستخدام `pd.read_excel()`
  - ما هو ملف إكسل؟
  - مثال عملي
  - قراءة عدة أوراق (sheets)
- قراءة ملف JSON باستخدام `pd.read_json()`
  - ما هو JSON؟
  - مثال عملي
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تحليل مبيعات شهرية
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 3: فحص معلومات الجدول: `info()` و `describe()` و `dtypes` و `isnull()`**
- مقدمة: لماذا نفحص الجدول؟
- `df.info()` — فحص عام للجدول
  - تحليل الناتج
- `df.dtypes` — معرفة نوع كل عمود
- `df.describe()` — الإحصاءات الوصفية
  - للبيانات الرقمية
  - للبيانات النصية (`include='object'`)
- `df.isnull()` و `df.notnull()` — اكتشاف القيم المفقودة
  - `isnull().sum()` لحساب القيم المفقودة
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تحليل جودة البيانات في شركة
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 4: الوصول إلى الأعمدة والصفوف باستخدام `loc` و `iloc`**
- مقدمة: لماذا نحتاج إلى `loc` و `iloc`؟
- الوصول إلى عمود واحد أو أكثر
  - `df['العمود']` vs `df[['العمود']]`
- `df.loc[]` — الوصول بالاسم (العلامة)
  - مثال: صف واحد، نطاق، مع شرط
- `df.iloc[]` — الوصول بالرقم (الفهرس العددي)
  - مثال: أول صف، آخر صف، نطاق
- مقارنة بين `loc` و `iloc`
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تحليل مبيعات متجر إلكتروني
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 5: الفلترة الشرطية باستخدام `&` و `|` و `isin()` و `between()`**
- مقدمة: لماذا الفلترة مهمة؟
- الفلترة الأساسية باستخدام الشروط المنطقية
- الشروط المتعددة: `&` (و) و `|` (أو)
  - القاعدة الذهبية: الأقواس
- استخدام `~` (NOT)
- `isin()` — التحقق من وجود القيمة في قائمة
- `between()` — التحقق من النطاق
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تحليل مبيعات متجر إلكتروني
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 6: التعديل داخل DataFrame**
- مقدمة: لماذا نحتاج إلى التعديل؟
- إنشاء عمود جديد
  - مباشرة بالاسم
  - باستخدام `assign()`
- التعديل على قيم موجودة
  - بالوصول المباشر
  - بالشرط
- حذف أعمدة وصفوف
  - باستخدام `drop()`
  - مع `inplace=True`
- إعادة تسمية الأعمدة باستخدام `rename()`
  - بقاموس
  - دفعة واحدة
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تحديث بيانات متجر إلكتروني
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 7: التعامل مع القيم المفقودة: `dropna` و `fillna` و `isnull`**
- مقدمة: لماذا القيم المفقودة مشكلة؟
- ما هي القيم المفقودة؟
- اكتشاف القيم المفقودة: `isnull()` و `notnull()`
  - `isnull().sum()` و `sum().sum()`
- حذف الصفوف أو الأعمدة: `dropna()`
  - حذف أي صف به قيمة مفقودة
  - حذف حسب عمود معين (`subset`)
  - حذف الأعمدة
- ملء القيم المفقودة: `fillna()`
  - بالقيمة 0
  - بقيم مختلفة لكل عمود
  - بالقيمة السابقة (`ffill`) أو التالية (`bfill`)
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تحليل قاعدة بيانات موظفين
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 8: التجميع باستخدام `groupby()`**
- مقدمة: لماذا نستخدم `groupby()`؟
- المبدأ الأساسي لـ `groupby()`
- أمثلة عملية
  - المجموع حسب الفئة
  - المتوسط، العد، الحجم
- تجميع متعدد الأعمدة باستخدام `agg()`
- التجميع حسب أكثر من عمود
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تقرير مبيعات شهري
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 9: ترتيب البيانات باستخدام `sort_values()`**
- مقدمة: لماذا نحتاج إلى الترتيب؟
- الترتيب الأساسي: تصاعدي وتنازلي
- الترتيب حسب أكثر من عمود
- الترتيب حسب الفهرس: `sort_index()`
- التحكم في وضع القيم المفقودة: `na_position`
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: قائمة أفضل الموظفين
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 10: دمج وربط البيانات باستخدام `merge` و `concat`**
- مقدمة: لماذا نحتاج إلى دمج البيانات؟
- الدمج الرأسي: `pd.concat()`
  - دمج عدة ملفات شهرية
  - دمج أفقي
- الربط بالعلاقة: `pd.merge()`
  - `on=`، `how='inner'`, `'left'`, `'outer'`, `'right'`
- أنواع الـ joins
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: نظام مبيعات متكامل
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 11: التعامل مع الأعمدة الزمنية: `pd.to_datetime()` و `.dt` و تصفية التواريخ**
- مقدمة: لماذا التواريخ مهمة؟
- تحويل النص إلى تاريخ: `pd.to_datetime()`
  - مع `format=`
- استخراج مكونات التاريخ: `.dt`
  - السنة، الشهر، اليوم، اليوم من الأسبوع، الربع
- تصفية البيانات حسب التاريخ
  - بين تاريخين، حسب الشهر
- `pd.Timestamp` و `pd.Timedelta`
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تحليل مبيعات ربع سنوية
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

---

## 📘 **الدرس 12: حفظ البيانات إلى ملفات باستخدام `to_csv` و `to_excel`**
- مقدمة: لماذا نحفظ البيانات؟
- حفظ إلى CSV: `to_csv()`
  - `index=False`, `encoding='utf-8-sig'`, `mode='a'`
- حفظ إلى إكسل: `to_excel()`
  - `ExcelWriter` لعدة أوراق
- حفظ إلى JSON: `to_json()`
- الأخطاء الشائعة (تحليل معمق)
- تمارين تطبيقية
- الربط بالواقع: تصدير تقرير شهري
- نصائح احترافية
- أسئلة مراجعة
- مراجعة سريعة (ملخص الدرس)

# 📘 **الدرس 1  : تعريف DataFrame وكيفية إنشائه من قائمة أو قاموس أو NumPy**

## 🔹 **مقدمة: لماذا Pandas؟ ولماذا DataFrame؟**

قبل أن نغوص في التفاصيل التقنية، دعنا نفهم السبب وراء وجود مكتبة مثل **Pandas**.

تخيل أنك تعمل في شركة تجارة إلكترونية، وتتلقى يوميًا ملفات تحتوي على:
- منتجات تم بيعها
- أسماء العملاء
- تواريخ الشراء
- الأسعار والكميات

هل ستستخدم **قائمة Python** أو **قائمة من القوائم** لتحليل هذه البيانات؟  
يمكنك ذلك، لكن ستصادف صعوبات كبيرة:
- لا يمكن فصل الأعمدة بسهولة.
- لا يمكن تطبيق العمليات الحسابية على عمود كامل بسهولة.
- لا يمكن تصفية البيانات حسب شرط معين بسلاسة.
- لا يمكن تجميع البيانات حسب فئة (مثل: مبيعات كل شهر).

هنا تأتي **Pandas** لحل هذه المشكلات.  
وأداة Pandas الأساسية هي الـ **DataFrame**.

---

## 🔹 **ما هو DataFrame؟ (شرح نظري مفصل)**

الـ `DataFrame` هو هيكل بيانات ثنائي الأبعاد (جدول) يشبه:
- جدول في **Excel**
- جدول في قاعدة بيانات مثل **MySQL**
- مصفوفة متقدمة في الرياضيات

### ✅ خصائص الـ DataFrame:
| الخاصية | الوصف |
|--------|-------|
| **أعمدة (Columns)** | كل عمود له اسم (مثل: "الاسم"، "السعر") |
| **صفوف (Rows)** | كل صف يمثل سجلًا (مثل: عميل واحد) |
| **فهرس (Index)** | رقم تسلسلي لكل صف (يبدأ من 0 غالبًا) |
| **أنواع بيانات مختلفة** | يمكن أن يكون عمود رقمي، وآخر نصي، وثالث تواريخ |
| **قابل للتوسيع** | يمكن إضافة أعمدة أو صفوف بسهولة |

### 🎯 تشبيه بسيط:
> 💡 اعتبر أن الـ `DataFrame` هو **سجل مدرسي**:
> - الأعمدة: "الاسم"، "العمر"، "الصف"، "الدرجة"
> - الصفوف: كل طالب
> - الفهرس: الرقم التسلسلي للطالب

---

## 🔹 **كيفية إنشاء DataFrame؟**

### ✅ الطريقة 1: من قاموس (Dict) — الأسهل والأكثر شيوعًا

القاموس في Python هو بنية بيانات تُخزن "مفتاح: قيمة".  
في Pandas، نستخدم القاموس بحيث:
- **المفتاح**: اسم العمود
- **القيمة**: قائمة بالقيم في ذلك العمود

#### 📌 المثال 1: إنشاء DataFrame لطلاب

```python
import pandas as pd

data = {
    'الاسم': ['خالد', 'نورة', 'فهد', 'منى'],
    'العمر': [18, 17, 19, 18],
    'الصف': ['ثاني ثانوي', 'أول ثانوي', 'ثاني ثانوي', 'ثالث ثانوي'],
    'الدرجة': [88, 94, 76, 91]
}

df_students = pd.DataFrame(data)
print(df_students)
```

#### 🔍 **الناتج:**

```
   الاسم  العمر       الصف  الدرجة
0   خالد     18  ثاني ثانوي     88
1   نورة     17  أول ثانوي     94
2   فهد     19  ثاني ثانوي     76
3   منى     18  ثالث ثانوي     91
```

> ✅ تم إنشاء جدول بـ 4 أعمدة و4 صفوف. الفهرس التلقائي من 0 إلى 3.

---

### ✅ الطريقة 2: من قائمة (List of Lists)

يمكنك إنشاء DataFrame من قائمة من الصفوف، حيث كل صف هو قائمة.

#### 📌 المثال 2: من قائمة

```python
rows = [
    ['تفاح', 3.5, 50],
    ['موز', 2.0, 30],
    ['حليب', 8.0, 20]
]

columns = ['المنتج', 'السعر', 'الكمية']
df_products = pd.DataFrame(rows, columns=columns)
print(df_products)
```

#### 🔍 الناتج:

```
  المنتج  السعر  الكمية
0   تفاح    3.5     50
1   موز    2.0     30
2  حليب    8.0     20
```

> ⚠️ **ملاحظة مهمة**: إذا لم تُدخل `columns=`، فسيُسمى الأعمدة تلقائيًا: 0, 1, 2...

---

### ✅ الطريقة 3: من مصفوفة NumPy

بما أن Pandas مبنية على NumPy، يمكنك استخدام مصفوفة NumPy.

#### 📌 المثال 3: باستخدام NumPy

```python
import numpy as np

data_np = np.array([
    ['أحمد', 25, 'الرياض'],
    ['سارة', 30, 'جدة'],
    ['علي', 22, 'الدمام']
])

df_employees = pd.DataFrame(data_np, columns=['الاسم', 'العمر', 'المدينة'])
print(df_employees)
```

#### 🔍 الناتج:

```
  الاسم  العمر  المدينة
0   أحمد     25    الرياض
1   سارة     30      جدة
2   علي      22    الدمام
```

> ⚠️ **تحذير**: جميع القيم أصبحت من نوع `object` (نص) لأن NumPy يُجبر المصفوفة على نوع بيانات واحد. العمر هنا ليس رقمًا يمكن حسابه!

---

### ✅ الطريقة 4: من قائمة من القواميس

مفيد جدًا عند التعامل مع بيانات من APIs.

```python
data_dicts = [
    {'اسم': 'أحمد', 'درجة': 85},
    {'اسم': 'سارة', 'درجة': 92},
    {'اسم': 'علي', 'درجة': 78}
]

df_grades = pd.DataFrame(data_dicts)
print(df_grades)
```

#### 🔍 الناتج:

```
   اسم  درجة
0  أحمد    85
1  سارة    92
2   علي    78
```

> ✅ مفيد جدًا في تحليل بيانات JSON من الإنترنت.

---

## 🔹 **فهم نوع البيانات (dtypes) عند الإنشاء**

لنفحص نوع البيانات:

```python
print(df_employees.dtypes)
```

#### 🔍 الناتج:

```
الاسم      object
العمر      object   ← ❌ ليس int!
المدينة    object
dtype: object
```

> ⚠️ **المشكلة**: العمر مُعامل كنص لأنه في مصفوفة نصوص.

### ✅ الحل: تحويل الأعمدة يدويًا

```python
df_employees['العمر'] = df_employees['العمر'].astype(int)
print(df_employees.dtypes)
```

> الآن العمر من نوع `int64`، ويمكنك حساب المتوسط:

```python
print("متوسط العمر:", df_employees['العمر'].mean())  # 25.67
```

---

## 🔹 **الأخطاء الشائعة عند الإنشاء (تحليل معمق)**

| الخطأ | السبب | كيف تكتشفه | الحل |
|------|------|------------|------|
| `ValueError: arrays must all be same length` | أحد الأعمدة أطول من الآخر | عند تشغيل `pd.DataFrame()` | تأكد أن كل قائمة لها نفس الطول |
| `KeyError` عند الوصول للعمود | خطأ إملائي في اسم العمود | عند استخدام `df['اسم']` | تحقق من الأسماء باستخدام `df.columns` |
| `NameError: name 'pd' is not defined` | لم تستورد Pandas | عند أول استخدام لـ `pd` | تأكد من `import pandas as pd` |
| `SettingWithCopyWarning` | تعديل على نسخة من DataFrame | عند التعديل بعد الفلترة | استخدم `.copy()` أو `.loc` |

---

## 🔹 **تمارين تطبيقية (من السهل إلى الصعب)**

### ✅ التمرين 1: إنشاء DataFrame بسيط
أنشئ DataFrame يحتوي على:
- الموظفين: ['سليمان', 'هدى', 'راشد']
- الرواتب: [8000, 9500, 7000]
- الإدارات: ['مبيعات', 'تسويق', 'مبيعات']

### ✅ التمرين 2: تصحيح خطأ
الكود التالي به خطأ. عيّنه وصحّحه:

```python
data = {
    'city': ['Riyadh', 'Jeddah'],
    'temp': [38, 35, 40]  # ← خطأ هنا
}
df = pd.DataFrame(data)
```

### ✅ التمرين 3: من قائمة إلى DataFrame
أنشئ DataFrame من القائمة التالية:

```python
data = [
    ['Product A', 100, 'Electronics'],
    ['Product B', 150, 'Clothing']
]
```

### ✅ التمرين 4: من NumPy مع تحويل نوع
استخدم `np.array` لإنشاء DataFrame، ثم حوّل عمود "السعر" إلى `float`.

---

## 🔹 **الربط بالواقع: مشروع صغير — إدارة متجر**

### 🎯 الهدف: إنشاء سجل مبيعات أولي

```python
sales_data = {
    'التاريخ': ['2023-01-01', '2023-01-01', '2023-01-02'],
    'المنتج': ['تفاح', 'موز', 'حليب'],
    'السعر': [3.5, 2.0, 8.0],
    'الكمية': [10, 15, 5],
    'الفئة': ['فواكه', 'فواكه', 'ألبان']
}

df_sales = pd.DataFrame(sales_data)
df_sales['الإجمالي'] = df_sales['السعر'] * df_sales['الكمية']

print(df_sales)
print("إجمالي المبيعات:", df_sales['الإجمالي'].sum())
```

#### 🔍 الناتج:

```
      التاريخ  المنتج  السعر  الكمية   الفئة  الإجمالي
0  2023-01-01   تفاح    3.5     10   فواكه      35.0
1  2023-01-01   موز    2.0     15   فواكه      30.0
2  2023-01-02  حليب    8.0      5   ألبان      40.0

إجمالي المبيعات: 105.0
```

> هذا هو الأساس لأي نظام تحليل مبيعات!

---

## 🔹 **نصائح احترافية للمبتدئين**

1. ✅ **استخدم `pd.DataFrame()` فقط مع بيانات منظمة** — لا تجبر بيانات معقدة على أن تصبح DataFrame.
2. ✅ **تحقق من `dtypes` دائمًا** — كثيرًا ما تكون الأرقام كنصوص.
3. ✅ **استخدم `df.head()` بعد الإنشاء** — للتأكد من أن البيانات تبدو صحيحة.
4. ✅ **لا تنسَ `import pandas as pd`** — خطأ شائع جدًا.
5. ✅ **احفظ الكود في ملف `.py` أو `Jupyter Notebook`** — أسهل للتجربة.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `Series` و `DataFrame`؟
2. لماذا نستخدم `columns=` عند إنشاء DataFrame من قائمة؟
3. ماذا يحدث إذا كانت إحدى القوائم في القاموس أقصر من الأخرى؟
4. كيف تتأكد من أن عمود "السعر" رقمي وليس نصيًا؟
5. ما الفائدة من استخدام `df.copy()` عند الفلترة؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| المفهوم | الوصف |
|--------|-------|
| `DataFrame` | جدول بيانات ثنائي الأبعاد |
| `pd.DataFrame(dict)` | الأسلوب الأكثر شيوعًا |
| `columns=` | لتحديد أسماء الأعمدة |
| `astype()` | لتحويل نوع البيانات |
| `dtypes` | لمعرفة نوع كل عمود |
| `head()` | لعرض أول 5 صفوف |

# 📘 **الدرس 2  : قراءة البيانات من ملفات CSV وExcel وJSON**

---

## 🔹 **مقدمة: لماذا نقرأ من ملفات؟**

في العالم الحقيقي، **نادرًا ما نُنشئ البيانات يدويًا**.  
البيانات تأتي من:
- ملفات CSV من أنظمة المحاسبة
- ملفات إكسل من المبيعات
- ملفات JSON من تطبيقات الجوال أو APIs

لذلك، **قراءة البيانات** هي أول خطوة في أي مشروع تحليل.

---

## 🔹 **1. قراءة ملف CSV باستخدام `pd.read_csv()`**

### ✅ ما هو ملف CSV؟
- **CSV** = Comma-Separated Values
- ملف نصي، كل صف يمثل سجل، وكل عمود يفصله فاصلة.
- مثالي للبيانات الكبيرة.

### 📌 المثال 1: قراءة ملف بسيط

افترض أن لديك ملف `employees.csv`:

```csv
الاسم,العمر,المدينة,الراتب
أحمد,25,الرياض,5000
سارة,30,جدة,7000
علي,22,الدمام,4000
```

الكود:

```python
df = pd.read_csv('employees.csv')
print(df)
```

#### 🔍 الناتج:

```
  الاسم  العمر  المدينة  الراتب
0   أحمد     25    الرياض  5000
1   سارة     30      جدة  7000
2   علي      22    الدمام  4000
```

> ✅ تم تحميل البيانات بنجاح.

---

### 🔹 **خيارات مهمة في `read_csv`**

| الخيار | الوظيفة | مثال |
|--------|--------|------|
| `sep` | تحديد الفاصل | `sep=';'` |
| `header` | رقم صف العناوين | `header=0` |
| `index_col` | جعل عمود فهرسًا | `index_col='الاسم'` |
| `encoding` | الترميز | `encoding='utf-8'` |
| `skiprows` | تخطي صفوف | `skiprows=1` |
| `nrows` | قراءة عدد محدد من الصفوف | `nrows=100` |

#### 📌 المثال 2: استخدام خيارات متقدمة

```python
df = pd.read_csv(
    'data.csv',
    sep=';',
    encoding='utf-8',
    index_col='ID',
    nrows=500
)
```

---

## 🔹 **2. قراءة ملف Excel باستخدام `pd.read_excel()`**

### ✅ ما هو ملف إكسل؟
- تنسيق `.xlsx` من Microsoft Excel.
- يمكن أن يحتوي على عدة أوراق (sheets).
- أكثر تعقيدًا من CSV.

### 📌 المثال 3: قراءة ورقة واحدة

```python
df = pd.read_excel('sales.xlsx', sheet_name='يناير')
print(df.head())
```

> ⚠️ تحتاج تثبيت `openpyxl`:
```bash
pip install openpyxl
```

### 📌 المثال 4: قراءة كل الأوراق

```python
all_sheets = pd.read_excel('sales.xlsx', sheet_name=None)
for sheet_name, data in all_sheets.items():
    print(f"--- ورقة: {sheet_name} ---")
    print(data.head())
```

---

## 🔹 **3. قراءة ملف JSON باستخدام `pd.read_json()`**

### ✅ ما هو JSON؟
- تنسيق شائع في واجهات برمجة التطبيقات (APIs).
- يُخزن البيانات كـ كائنات أو مصفوفات.

### 📌 المثال 5: من ملف JSON

ملف `users.json`:

```json
[
  {"name": "Ahmed", "age": 25, "city": "Riyadh"},
  {"name": "Sara", "age": 30, "city": "Jeddah"}
]
```

الكود:

```python
df = pd.read_json('users.json')
print(df)
```

> ✅ يعمل بشكل جيد مع المصفوفات من الكائنات.

---

## 🔹 **الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `FileNotFoundError` | الملف غير موجود | تحقق من المسار والاسم |
| `UnicodeDecodeError` | ترميز خاطئ | استخدم `encoding='utf-8'` |
| `EmptyDataError` | الملف فارغ | تحقق من محتوى الملف |
| `ParserError` | تنسيق CSV تالف | استخدم `error_bad_lines=False` (قديم) أو `on_bad_lines='skip'` (جديد) |

---

## 🔹 **تمارين تطبيقية**

1. أنشئ ملف CSV باسم `grades.csv` واملأه ببيانات طلاب، ثم اقرأه.
2. كيف تقرأ ورقة محددة من ملف إكسل به 3 أوراق؟
3. ما الفرق بين `read_csv` و `read_table`؟
4. كيف تقرأ أول 10 صفوف فقط من ملف كبير جدًا؟

---

## 🔹 **الربط بالواقع: تحليل مبيعات شهرية**

افترض أنك قرأت ملفات مبيعات من 3 أشهر:

```python
jan = pd.read_csv('jan.csv')
feb = pd.read_csv('feb.csv')
mar = pd.read_csv('mar.csv')

total_sales = pd.concat([jan, feb, mar])
print("إجمالي المبيعات:", total_sales['الإجمالي'].sum())
```

> هذا هو الأساس لتحليل أداء الشركة!

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم `df.shape` بعد القراءة — للتأكد من عدد الصفوف والأعمدة.
2. ✅ استخدم `df.head()` و `df.tail()` — لفحص بداية ونهاية البيانات.
3. ✅ احفظ مسارات الملفات في متغيرات — لسهولة التعديل.
4. ✅ استخدم `try-except` عند القراءة — لتجنب توقف البرنامج.

# 📘 **الدرس 3  : فحص معلومات الجدول: `info()` و `describe()` و `dtypes` و `isnull()`**

## 🔹 **مقدمة: لماذا نفحص الجدول؟**

تخيل أنك طبيب، وتم إعطاؤك مريضًا جديدًا. أول ما تفعله هو:
- فحص العلامات الحيوية
- تحليل الدم
- التأكد من عدم وجود أعراض خطيرة

نفس الشيء ينطبق على **تحليل البيانات**.  
قبل أن تبدأ في الحساب أو التصوير البياني، يجب أن **تفحص الجدول جيدًا** للتأكد من:
- صحة الأنواع (هل العمر رقم أم نص؟)
- وجود قيم مفقودة
- عدد الصفوف والأعمدة
- هل البيانات منطقية؟

هذا هو هدف هذا الدرس: **الاستعداد الجيد لأي تحليل بيانات**.

---

## 🔹 **1. `df.info()` — فحص عام للجدول**

### ✅ ماذا يعرض `info()`؟
- عدد الصفوف (الإدخالات)
- عدد الأعمدة
- اسم كل عمود
- عدد القيم غير المفقودة (Non-Null Count)
- نوع البيانات (dtype)
- استهلاك الذاكرة

### 📌 المثال 1: استخدام `info()` على بيانات الموظفين

```python
import pandas as pd

data = {
    'الاسم': ['أحمد', 'سارة', 'علي', 'نورة'],
    'العمر': [25, 30, 22, 28],
    'المدينة': ['الرياض', 'جدة', 'الدمام', None],
    'الراتب': [5000, 7000, 4000, 6000]
}

df = pd.DataFrame(data)
df.info()
```

#### 🔍 **الناتج:**

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 4 entries, 0 to 3
Data columns (total 4 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   الاسم     4 non-null      object 
 1   العمر     4 non-null      int64  
 2   المدينة    3 non-null      object 
 3   الراتب     4 non-null      int64  
dtypes: int64(2), object(2)
memory usage: 200.0+ bytes
```

### 🔍 **تحليل الناتج:**
- هناك 4 صفوف (من 0 إلى 3).
- العمود "المدينة" به 3 قيم غير مفقودة فقط → هناك **قيمة مفقودة واحدة**.
- العمر والراتب من نوع `int64` (أعداد صحيحة).
- الاسم والمدينة من نوع `object` (غالبًا نصوص).
- الذاكرة المستهلكة صغيرة جدًا (200 بايت).

> ✅ هذا الكشف عن القيمة المفقودة في "المدينة" هو **معلومة حيوية**!

---

## 🔹 **2. `df.dtypes` — معرفة نوع كل عمود**

### ✅ متى نستخدمه؟
عندما نريد التحقق بسرعة من أنواع البيانات، دون تفاصيل إضافية.

```python
print(df.dtypes)
```

#### 🔍 الناتج:

```
الاسم      object
العمر       int64
المدينة     object
الراتب       int64
dtype: object
```

> ⚠️ **تحذير شائع**: إذا كان عمود "العمر" من نوع `object`، فهذا يعني أنه **نص**، ولا يمكن حساب المتوسط عليه!

### ✅ كيف تكتشف المشكلة؟

```python
if df['العمر'].dtype == 'object':
    print("تحذير: العمر ليس رقمًا!")
```

---

## 🔹 **3. `df.describe()` — الإحصاءات الوصفية**

### ✅ ماذا يفعل؟
يُظهر ملخصًا إحصائيًا **للأعمدة الرقمية فقط**:
- العدد (count)
- المتوسط (mean)
- الانحراف المعياري (std)
- القيم الدنيا والعليا (min, max)
- الرباعيات (25%, 50%, 75%)

### 📌 المثال 2: وصف الإحصائيات

```python
print(df.describe())
```

#### 🔍 الناتج:

```
           العمر         الراتب
count   4.000000      4.000000
mean   26.250000   5500.000000
std     3.593977   1290.994427
min    22.000000   4000.000000
25%    24.250000   4750.000000
50%    26.500000   5500.000000
75%    27.500000   6250.000000
max    30.000000   7000.000000
```

### 🔍 **تحليل النتائج:**
- متوسط العمر: 26.25 سنة
- أعلى راتب: 7000 ريال
- 75% من الرواتب أقل من 6250

> ✅ هذه المعلومات مفيدة جدًا في تقارير الموارد البشرية.

---

### ✅ كيف تعرض الأعمدة النصية في `describe()`؟

باستخدام `include='object'`:

```python
print(df.describe(include='object'))
```

#### 🔍 الناتج:

```
       الاسم    المدينة     الراتب
count     4         3         4
unique    4         3         4
top     نورة      جدة      5000
freq      1         1         1
```

> - `unique`: عدد القيم المختلفة
> - `top`: القيمة الأكثر تكرارًا
> - `freq`: عدد مرات التكرار

---

## 🔹 **4. `df.isnull()` و `df.notnull()` — اكتشاف القيم المفقودة**

### ✅ ما هي القيم المفقودة؟
- تمثّل بـ `NaN` (Not a Number)
- تحدث بسبب: بيانات ناقصة، خطأ في الإدخال، عدم توفر المعلومات

### 📌 المثال 3: استخدام `isnull()`

```python
print(df.isnull())
```

#### 🔍 الناتج:

```
    الاسم   العمر  المدينة   الراتب
0  False  False   False   False
1  False  False   False   False
2  False  False   False   False
3  False  False    True   False
```

> ✅ فقط خلية "المدينة" في الصف 3 هي `NaN`.

### ✅ كم عدد القيم المفقودة في كل عمود؟

```python
print(df.isnull().sum())
```

#### 🔍 الناتج:

```
الاسم      0
العمر      0
المدينة    1
الراتب      0
dtype: int64
```

> مثالي للإبلاغ عن جودة البيانات.

---

## 🔹 **الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `AttributeError: 'DataFrame' object has no attribute 'infos'` | كتابة `info` بدون أقواس أو خطأ إملائي | تأكد من `df.info()` |
| `describe()` لا يعرض عمودًا معينًا | لأن العمود نصي وليس رقمي | استخدم `include='all'` أو `'object'` |
| `isnull()` لا يُظهر شيئًا | لأن البيانات كاملة | جيّد! لا مشكلة |
| `dtypes` تُظهر `object` لعمود رقمي | بسبب وجود نصوص أو `NaN` في العمود | نظّف البيانات ثم حوّل النوع |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: افحص جدولك
أنشئ DataFrame يحتوي على:
- الطلاب: ['خالد', 'منى', 'فهد']
- الدرجات: [85, None, 78]
ثم استخدم `info()` و `isnull()` لتحديد المشكلة.

### ✅ التمرين 2: فهم الناتج
لماذا لا يظهر عمود "الاسم" في `describe()`؟ كيف تجعله يظهر؟

### ✅ التمرين 3: تحليل جودة البيانات
ما الفرق بين `df.isnull().sum()` و `df.notnull().sum()`؟

### ✅ التمرين 4: تحليل واقعي
لديك ملف مبيعات. استخدم `describe()` لمعرفة:
- متوسط السعر
- أقل كمية مباعة
- التباين في الإيرادات

---

## 🔹 **الربط بالواقع: تحليل جودة البيانات في شركة**

### 🎯 الهدف: إعداد تقرير جودة البيانات

```python
def quality_report(df):
    print("=== تقرير جودة البيانات ===")
    print(f"عدد الصفوف: {df.shape[0]}")
    print(f"عدد الأعمدة: {df.shape[1]}")
    print(f"القيم المفقودة: \n{df.isnull().sum()}")
    print(f"أنواع البيانات: \n{df.dtypes}")
    print(f"الإحصاءات: \n{df.describe()}")

quality_report(df)
```

> ✅ هذا التقرير يُستخدم في المؤسسات الكبيرة قبل أي تحليل.

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم `df.info()` أول شيء بعد قراءة الملف.
2. ✅ استخدم `df.isnull().sum()` لتقييم جودة البيانات.
3. ✅ لا تثق في `describe()` وحده — فاحص الأعمدة النصية يدويًا.
4. ✅ إذا كان عمود رقمي يُعرض كـ `object`، فافحصه بـ `pd.to_numeric()`.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `info()` و `describe()`؟
2. كيف تعرف إذا كان عمود يحتوي على قيم مفقودة؟
3. لماذا لا يُعرض العمود النصي في `describe()` افتراضيًا؟
4. ما معنى `Non-Null Count` في `info()`؟
5. كيف تُظهر الإحصاءات للأعمدة النصية؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الدالة | الوظيفة |
|-------|--------|
| `df.info()` | معلومات شاملة عن الجدول |
| `df.dtypes` | أنواع البيانات لكل عمود |
| `df.describe()` | إحصائيات للأعمدة الرقمية (ويمكن تضمين النصية) |
| `df.isnull()` | كشف القيم المفقودة |
| `df.isnull().sum()` | عدد القيم المفقودة لكل عمود |

# 📘 **الدرس 4  : الوصول إلى الأعمدة والصفوف باستخدام `loc` و `iloc`**

## 🔹 **مقدمة: لماذا نحتاج إلى `loc` و `iloc`؟**

حتى الآن، تعلمت كيف:
- تُنشئ DataFrame
- تقرأ بيانات من ملفات
- تفحص جودتها

لكن ماذا لو أردت:
- استخراج **اسم الموظف الثالث**؟
- عرض **السعر والكمية فقط** لمنتج معين؟
- تعديل **درجة طالب معين**؟

هنا تأتي أهمية **الوصول الدقيق إلى البيانات**.

في Python، نستخدم الفهارس مثل `list[0]`، لكن في Pandas، لدينا أدوات أكثر ذكاءً:
- `loc`: للوصول بالـ **أسماء (العلامات)**
- `iloc`: للوصول بالـ **الأرقام (الفهارس العددية)**

> 💡 اعتبر أن `loc` مثل "البحث باسم"، و `iloc` مثل "البحث برقم التسلسل".

---

## 🔹 **1. الوصول إلى عمود واحد أو أكثر**

### ✅ الطريقة 1: باستخدام الأقواس المربعة

```python
import pandas as pd

data = {
    'الاسم': ['أحمد', 'سارة', 'علي'],
    'العمر': [25, 30, 22],
    'المدينة': ['الرياض', 'جدة', 'الدمام'],
    'الراتب': [5000, 7000, 4000]
}
df = pd.DataFrame(data)

# الوصول إلى عمود واحد
print(df['الاسم'])
```

#### 🔍 الناتج (Series):
```
0    أحمد
1    سارة
2     علي
Name: الاسم, dtype: object
```

> ⚠️ ملاحظة: الناتج هو `Series` (عمود واحد)، وليس `DataFrame`.

### ✅ الطريقة 2: لاسترجاع عمود كـ DataFrame

```python
print(df[['الاسم']])
```

#### 🔍 الناتج (DataFrame):
```
   الاسم
0   أحمد
1   سارة
2   علي
```

> ✅ الفرق: استخدام **قوسين مربعين** يجعل الناتج DataFrame.

---

## 🔹 **2. `df.loc[]` — الوصول بالاسم (العلامة - label)**

### ✅ الصيغة:
```python
df.loc[الصفوف, الأعمدة]
```

### 📌 المثال 1: صف واحد، عمود واحد

```python
print(df.loc[0, 'الاسم'])  # أحمد
```

---

### 📌 المثال 2: نطاق من الصفوف، وأعمدة محددة

```python
result = df.loc[0:1, ['الاسم', 'العمر']]
print(result)
```

#### 🔍 الناتج:
```
  الاسم  العمر
0   أحمد     25
1   سارة     30
```

> ✅ `loc` **يشمل الحد الأخير** (0:1 تعني الصف 0 و1 معًا).

---

### 📌 المثال 3: جميع الصفوف، عمود معين

```python
print(df.loc[:, 'الراتب'])
```

> ✅ `:` تعني "كل الصفوف" أو "كل الأعمدة".

---

### 📌 المثال 4: شرط ديناميكي (مزيج من الفلترة والوصول)

```python
# أسماء الموظفين الذين رواتبهم أعلى من 5000
high_earners = df.loc[df['الراتب'] > 5000, 'الاسم']
print(high_earners)
```

#### 🔍 الناتج:
```
1    سارة
Name: الاسم, dtype: object
```

> ✅ هذا مزيج قوي: فلترة + استخراج عمود.

---

## 🔹 **3. `df.iloc[]` — الوصول بالرقم (الفهرس العددي - index)**

### ✅ الصيغة:
```python
df.iloc[الصفوف (برقم), الأعمدة (برقم)]
```

### 📌 المثال 1: أول صف، أول عمود

```python
print(df.iloc[0, 0])  # أحمد
```

---

### 📌 المثال 2: أول صفوفين، أول عمودين

```python
result = df.iloc[0:2, 0:2]
print(result)
```

#### 🔍 الناتج:
```
  الاسم  العمر
0   أحمد     25
1   سارة     30
```

> ⚠️ `iloc` **لا يشمل الحد الأخير** (0:2 تعني الصف 0 و1 فقط).

---

### 📌 المثال 3: آخر صف، جميع الأعمدة

```python
print(df.iloc[-1, :])
```

#### 🔍 الناتج:
```
الاسم       علي
العمر        22
المدينة    الدمام
الراتب      4000
Name: 2, dtype: object
```

---

### 📌 المثال 4: أعمدة محددة برقم

```python
# العودة إلى الأعمدة 1 و3 (العمر والراتب)
print(df.iloc[:, [1, 3]])
```

#### 🔍 الناتج:
```
   العمر  الراتب
0     25   5000
1     30   7000
2     22   4000
```

---

## 🔹 **مقارنة بين `loc` و `iloc`**

| الميزة | `loc` | `iloc` |
|--------|------|--------|
| الأساس | الاسم (العلامة) | الرقم (الفهرس) |
| يشمل الحد الأخير؟ | نعم | لا |
| يمكنه استخدام شروط؟ | نعم (مثلاً `df['الراتب']>5000`) | لا، فقط أرقام |
| مثال | `df.loc[0:2, 'الاسم':'العمر']` | `df.iloc[0:2, 0:2]` |

> 💡 تذكر:  
> - **`loc` → label-based**  
> - **`iloc` → integer-based**

---

## 🔹 **الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `KeyError` | اسم عمود غير موجود | تحقق من `df.columns` |
| `IndexError` | رقم صف/عمود خارج النطاق | تحقق من `df.shape` |
| `df.loc[0]` يُرجع Series | نعم، هذا السلوك الطبيعي | استخدم `df.loc[[0]]` للحصول على DataFrame |
| `df.loc['0']` لا يعمل | لأن الفهرس رقم، وليس نص | استخدم `iloc` أو تأكد من نوع الفهرس |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: استخراج البيانات
استخدم `iloc` لاستخراج:
- الصف الثاني فقط
- العمود الثالث (المدينة)

### ✅ التمرين 2: استخدام `loc` مع شرط
استخدم `loc` لعرض:
- أسماء ورواتب الموظفين الذين أعمارهم أقل من 28

### ✅ التمرين 3: خطأ شائع
لماذا هذا الكود يعطي `KeyError`؟
```python
df.loc[0, 'الإسم']  # ملاحظة: همزة على الاسم
```

### ✅ التمرين 4: دمج `loc` و `iloc`
هل يمكن دمج `loc` و `iloc` في نفس العملية؟ لماذا؟

---

## 🔹 **الربط بالواقع: تحليل مبيعات متجر إلكتروني**

### 🎯 الهدف: استخراج معلومات دقيقة عن المبيعات

```python
sales = pd.DataFrame({
    'التاريخ': ['2023-01-01', '2023-01-01', '2023-01-02'],
    'المنتج': ['تفاح', 'موز', 'حليب'],
    'السعر': [3.5, 2.0, 8.0],
    'الكمية': [10, 15, 5],
    'الفئة': ['فواكه', 'فواكه', 'ألبان']
})

# 1. أول عملية بيع (كـ سطر كامل)
first_sale = sales.iloc[0, :]
print("أول عملية بيع:\n", first_sale)

# 2. المنتجات والأسعار فقط للصفوف من 0 إلى 1
products_prices = sales.loc[0:1, ['المنتج', 'السعر']]
print("\nالمنتجات والأسعار:\n", products_prices)

# 3. كل المبيعات في فئة "فواكه"
fruits_sales = sales.loc[sales['الفئة'] == 'فواكه', ['المنتج', 'الكمية']]
print("\nمبيعات الفواكه:\n", fruits_sales)
```

> ✅ هذا النوع من الاستعلامات هو أساس تقارير الأعمال.

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم `loc` عندما تعرف أسماء الأعمدة.
2. ✅ استخدم `iloc` عندما تعمل برقم التسلسل (مثلاً: أول 5 صفوف).
3. ✅ لا تخلط بين `df['العمود']` و `df[['العمود']]` — الأول يُرجع Series، الثاني DataFrame.
4. ✅ استخدم `df.columns.tolist()` لرؤية أسماء الأعمدة بدقة.
5. ✅ تجنب `df[0]` — لا يعمل إلا إذا كان الفهرس نصيًا.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `df['الاسم']` و `df[['الاسم']]`؟
2. لماذا `iloc[0:2]` يُرجع صفين فقط، بينما `loc[0:2]` يُرجع ثلاثة؟
3. كيف تُرجع آخر 3 صفوف باستخدام `iloc`؟
4. ما نوع البيانات الذي يُرجعه `loc` عندما تختار صفًا واحدًا؟
5. متى نستخدم `:` في `loc` أو `iloc`؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الأداة | الاستخدام |
|-------|----------|
| `df['العمود']` | عمود واحد كـ Series |
| `df[['العمود']]` | عمود واحد كـ DataFrame |
| `df.loc[แถว, عمود]` | بالاسم |
| `df.iloc[رقم, رقم]` | بالرقم |
| `:` | جميع الصفوف أو جميع الأعمدة |
| شرط داخل `loc` | دمج الفلترة مع الاستخراج |

# 📘 **الدرس 5  : الفلترة الشرطية باستخدام `&` و `|` و `isin()` و `between()`**

## 🔹 **مقدمة: لماذا الفلترة مهمة؟**

تخيل أنك مدير مبيعات، وتحصل على جدول يحتوي على 10,000 صف من عمليات البيع.  
لكنك ترغب فقط في معرفة:

- ما هي المبيعات التي **تجاوز سعرها 100 ريال**؟
- ما هي المنتجات من نوع **"إلكترونيات" أو "أجهزة منزلية"**؟
- ما هي المبيعات التي حدثت بين **يناير ومارس**؟

هنا تأتي أهمية **الفلترة الشرطية**.

الفلترة هي عملية **استخراج جزء من البيانات يطابق شرطًا معينًا**، وهي واحدة من أكثر العمليات استخدامًا في تحليل البيانات.

---

## 🔹 **1. الفلترة الأساسية باستخدام الشروط المنطقية**

### ✅ الطريقة: استخدام الأقواس `[]` مع شرط

```python
import pandas as pd

data = {
    'المنتج': ['تفاح', 'موز', 'لابتوب', 'سماعة', 'حليب'],
    'السعر': [3.5, 2.0, 2500, 150, 8.0],
    'الفئة': ['فواكه', 'فواكه', 'إلكترونيات', 'إلكترونيات', 'ألبان'],
    'الكمية': [50, 30, 5, 20, 40]
}
df = pd.DataFrame(data)

# المبيعات التي السعر فيها أكبر من 100
expensive = df[df['السعر'] > 100]
print(expensive)
```

#### 🔍 الناتج:
```
   المنتج    السعر       الفئة  الكمية
2   لابتوب  2500.0  إلكترونيات      5
3  سماعة   150.0  إلكترونيات     20
```

> ✅ فقط الصفوف التي تحقق الشرط تم عرضها.

---

## 🔹 **2. الشروط المتعددة: `&` (و) و `|` (أو)**

### ✅ القاعدة الذهبية:
- استخدم `&` بدل `and`
- استخدم `|` بدل `or`
- **ضع كل شرط بين قوسين**

### 📌 المثال 1: استخدام `&` (AND)

```python
# منتجات في فئة "إلكترونيات" وسعرها أكثر من 200
electronics_high = df[(df['الفئة'] == 'إلكترونيات') & (df['السعر'] > 200)]
print(electronics_high)
```

#### 🔍 الناتج:
```
  المنتج    السعر       الفئة  الكمية
2  لابتوب  2500.0  إلكترونيات      5
```

> ⚠️ بدون الأقواس: خطأ منطقي أو `TypeError`.

---

### 📌 المثال 2: استخدام `|` (OR)

```python
# منتجات إما "فواكه" أو سعرها أقل من 10
fruits_or_cheap = df[(df['الفئة'] == 'فواكه') | (df['السعر'] < 10)]
print(fruits_or_cheap)
```

#### 🔍 الناتج:
```
  المنتج  السعر  الفئة  الكمية
0   تفاح    3.5  فواكه     50
1   موز    2.0  فواكه     30
4  حليب    8.0   ألبان     40
```

> ✅ تم تضمين "حليب" لأنه رخيص، رغم أنه ليس فاكهة.

---

### 📌 المثال 3: استخدام `~` (NOT)

```python
# كل المنتجات ما عدا الفواكه
not_fruits = df[~(df['الفئة'] == 'فواكه')]
print(not_fruits)
```

#### 🔍 الناتج:
```
   المنتج    السعر       الفئة  الكمية
2   لابتوب  2500.0  إلكترونيات      5
3  سماعة   150.0  إلكترونيات     20
4   حليب     8.0      ألبان     40
```

> ✅ `~` تعني "عكس الشرط".

---

## 🔹 **3. `isin()` — التحقق من وجود القيمة في قائمة**

مفيد جدًا عندما تريد تصفية حسب **قائمة من القيم**.

### 📌 المثال 4: استخدام `isin()`

```python
# المنتجات التي اسمها "تفاح" أو "موز" أو "حليب"
selected = df[df['المنتج'].isin(['تفاح', 'موز', 'حليب'])]
print(selected)
```

#### 🔍 الناتج:
```
  المنتج  السعر  الفئة  الكمية
0   تفاح    3.5  فواكه     50
1   موز    2.0  فواكه     30
4  حليب    8.0   ألبان     40
```

> ✅ بديل أسرع من كتابة `==` متعددة.

---

## 🔹 **4. `between()` — التحقق من النطاق (شامل للنهايات)**

مفيد للأسعار، التواريخ، الأعمار...

### 📌 المثال 5: استخدام `between()`

```python
# المنتجات التي سعرها بين 5 و200
mid_price = df[df['السعر'].between(5, 200)]
print(mid_price)
```

#### 🔍 الناتج:
```
  المنتج  السعر       الفئة  الكمية
3  سماعة  150.0  إلكترونيات     20
4   حليب    8.0       ألبان     40
```

> ✅ `between()` يشمل القيم 5 و200.

---

## 🔹 **5. الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `TypeError: cannot compare` | نوع البيانات خاطئ (نص بدل رقم) | تأكد من `df.dtypes` |
| `ValueError: The truth value of a Series is ambiguous` | نسيان الأقواس حول الشروط | استخدم `(condition1) & (condition2)` |
| `KeyError` | اسم عمود غير موجود | تحقق من `df.columns` |
| `isin()` لا يُرجع نتائج | القيم لا تطابق تمامًا (مثلاً: فراغات) | نظّف البيانات أولًا |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: فلترة مزدوجة
أوجد المنتجات التي:
- الفئة: "إلكترونيات"
- الكمية: أقل من 10

### ✅ التمرين 2: استخدام `isin()` مع أرقام
استخدم `isin()` لعرض المنتجات التي كميتها 5 أو 20 أو 40.

### ✅ التمرين 3: خطأ شائع
لماذا هذا الكود لا يعمل؟
```python
df[df['السعر'] > 100 and df['الفئة'] == 'إلكترونيات']
```

### ✅ التمرين 4: نطاق تواريخ (مقدمة)
افترض أن لديك عمود تواريخ، كيف تُرجع الصفوف بين 2023-01-01 و2023-01-31؟ (سنشرح التواريخ لاحقًا)

---

## 🔹 **الربط بالواقع: تحليل مبيعات متجر إلكتروني**

### 🎯 الهدف: تحديد المنتجات المستهدفة

```python
# 1. المنتجات المربحة (سعر > 1000)
profitable = df[df['السعر'] > 1000]
print("المنتجات المربحة:\n", profitable)

# 2. المنتجات الشائعة (كمية > 30)
popular = df[df['الكمية'] > 30]
print("\nالمنتجات الشائعة:\n", popular)

# 3. المنتجات في فئات معينة
target_categories = df[df['الفئة'].isin(['إلكترونيات', 'فواكه'])]
print("\nالفئات المستهدفة:\n", target_categories)

# 4. منتجات بسعر متوسط (بين 10 و500)
mid_range = df[df['السعر'].between(10, 500)]
print("\nالسعر المتوسط:\n", mid_range)
```

> ✅ هذه الفلاتر تُستخدم في تقارير المبيعات، تحديد الحملات التسويقية، وإدارة المخزون.

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم `()` حول كل شرط عند استخدام `&` أو `|`.
2. ✅ تجنب `and` و `or` — فهي لا تعمل مع Series.
3. ✅ استخدم `isin()` بدل سلسلة من `==` مع `|`.
4. ✅ تحقق من أنواع البيانات قبل الفلترة (خاصة السعر والعمر).
5. ✅ استخدم `reset_index(drop=True)` بعد الفلترة إذا أردت فهرسًا جديدًا.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `&` و `and` في Pandas؟
2. لماذا يجب وضع الأقواس حول الشروط عند استخدام `&`؟
3. ماذا يفعل `~` في الفلترة؟
4. كيف تُرجع الصفوف التي لا تطابق شرطًا معينًا؟
5. ما الفرق بين `between(5, 10)` و `(df['x'] >= 5) & (df['x'] <= 10)`؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الدالة | الاستخدام |
|-------|----------|
| `df[condition]` | الفلترة الأساسية |
| `&` | AND (مع أقواس) |
| `|` | OR (مع أقواس) |
| `~` | NOT |
| `.isin(list)` | التحقق من وجود في قائمة |
| `.between(a, b)` | التحقق من النطاق (شامل) |

# 📘 **الدرس 6  : التعديل داخل DataFrame: إنشاء أعمدة جديدة، التعديل على قيم موجودة، حذف أعمدة وصفوف، إعادة التسمية**

## 🔹 **مقدمة: لماذا نحتاج إلى التعديل؟**

حتى الآن، تعلمت كيف:
- تُنشئ DataFrame
- تقرأ البيانات
- تفحصها
- تستخرج جزءًا منها بالفلترة

لكن في الواقع، **نادرًا ما تكون البيانات جاهزة تمامًا**.  
غالبًا ما نحتاج إلى:
- إضافة عمود جديد (مثل: "الإجمالي = السعر × الكمية")
- تعديل قيمة خاطئة
- حذف عمود غير مفيد
- تغيير اسم عمود ليكون أكثر وضوحًا

هذا هو هدف هذا الدرس: **تحويل البيانات إلى شكل تحليلي مفيد**.

---

## 🔹 **1. إنشاء عمود جديد**

### ✅ الطريقة 1: مباشرة بالاسم

```python
import pandas as pd

data = {
    'المنتج': ['تفاح', 'موز', 'لابتوب'],
    'السعر': [3.5, 2.0, 2500],
    'الكمية': [50, 30, 5]
}
df = pd.DataFrame(data)

# إنشاء عمود "الإجمالي"
df['الإجمالي'] = df['السعر'] * df['الكمية']
print(df)
```

#### 🔍 الناتج:
```
  المنتج  السعر  الكمية  الإجمالي
0   تفاح    3.5     50    175.0
1   موز    2.0     30     60.0
2  لابتوب  2500     5  12500.0
```

> ✅ تم إنشاء العمود الجديد تلقائيًا.

---

### ✅ الطريقة 2: باستخدام `assign()` (غير مدمر - لا يُعدّل الأصل)

مفيد في الأنابيب (pipelines).

```python
df_new = df.assign(ضريبة = df['الإجمالي'] * 0.15)
print(df_new)
```

#### 🔍 الناتج:
```
  المنتج  السعر  الكمية  الإجمالي   ضريبة
0   تفاح    3.5     50    175.0   26.25
1   موز    2.0     30     60.0    9.00
2  لابتوب  2500     5  12500.0 1875.00
```

> ✅ `assign()` يُعيد نسخة جديدة، ولا يُعدّل الأصل.

---

## 🔹 **2. التعديل على قيم موجودة**

### ✅ الطريقة 1: بالوصول المباشر

```python
# تصحيح سعر الموز
df.loc[1, 'السعر'] = 2.5
print(df)
```

#### 🔍 الناتج:
```
  المنتج  السعر  الكمية  الإجمالي
0   تفاح    3.5     50    175.0
1   موز    2.5     30     75.0  ← تغير
2  لابتوب  2500     5  12500.0
```

> ✅ تم تعديل القيمة بنجاح.

---

### ✅ الطريقة 2: بالشرط (مثلاً: رفع السعر 10% على المنتجات الرخيصة)

```python
# رفع السعر 10% على المنتجات التي أقل من 10
df.loc[df['السعر'] < 10, 'السعر'] = df['السعر'] * 1.1

# تحديث "الإجمالي" بعد التغيير
df['الإجمالي'] = df['السعر'] * df['الكمية']
print(df)
```

#### 🔍 الناتج:
```
  المنتج  السعر  الكمية  الإجمالي
0   تفاح    3.85     50    192.5
1   موز    2.75     30     82.5
2  لابتوب  2500.00    5  12500.0
```

> ✅ التعديل الشرطي مفيد جدًا في التحديثات الدفعية.

---

## 🔹 **3. حذف أعمدة وصفوف**

### ✅ حذف أعمدة باستخدام `drop()`

```python
# حذف عمود "الإجمالي"
df = df.drop(columns=['الإجمالي'])
print(df)
```

> ✅ يمكن حذف أكثر من عمود: `columns=['A', 'B']`

---

### ✅ حذف صفوف باستخدام `drop()`

```python
# حذف الصف رقم 2 (اللابتوب)
df = df.drop(index=2)
print(df)
```

#### 🔍 الناتج:
```
  المنتج  السعر  الكمية
0   تفاح    3.85     50
1   موز    2.75     30
```

> ⚠️ `drop()` لا يُعدّل الجدول الأصلي إلا إذا استخدمت `inplace=True`.

---

### ✅ استخدام `inplace=True`

```python
df.drop(columns=['الكمية'], inplace=True)
```

> ✅ لا يُعيد DataFrame، بل يُعدّل الأصل مباشرة.

---

## 🔹 **4. إعادة تسمية الأعمدة باستخدام `rename()`**

### ✅ الطريقة 1: بقاموس (الأفضل)

```python
df = df.rename(columns={'المنتج': 'الصنف', 'السعر': 'السعر النهائي'})
print(df)
```

#### 🔍 الناتج:
```
   الصنف  السعر النهائي
0    تفاح         3.85
1     موز         2.75
```

---

### ✅ الطريقة 2: إعادة تسمية كل الأعمدة دفعة واحدة

```python
df.columns = ['Product', 'Price']
print(df)
```

> ⚠️ خطر إذا تغير ترتيب الأعمدة لاحقًا.

---

## 🔹 **الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `SettingWithCopyWarning` | تعديل على نسخة من DataFrame | استخدم `.copy()` أو `loc` |
| `KeyError` عند الحذف | اسم عمود غير موجود | تحقق من `df.columns` |
| `inplace=True` لا يعمل مع `assign()` | لأن `assign()` لا يدعمه | احفظ الناتج: `df = df.assign(...)` |
| تعديل لا يظهر | لأنك لم تُعدّل الأصل أو لم تُستخدم `inplace` | تحقق من إرجاع القيمة |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: إنشاء عمود جديد
أضف عمودًا جديدًا اسمه "الضريبة" = 15% من "الإجمالي".

### ✅ التمرين 2: تعديل شرطي
ارفع السعر 20% على المنتجات التي "الإجمالي" فيها أقل من 100.

### ✅ التمرين 3: حذف متعدد
احذف العمودين "السعر" و"الكمية" دفعة واحدة.

### ✅ التمرين 4: إعادة تسمية
غيّر أسماء جميع الأعمدة إلى إنجليزية:  
`{'المنتج': 'Product', 'السعر': 'Price', 'الكمية': 'Quantity'}`

---

## 🔹 **الربط بالواقع: تحديث بيانات متجر إلكتروني**

### 🎯 الهدف: تحضير البيانات للتحليل النهائي

```python
# 1. إضافة عمود "الإجمالي"
df['Total'] = df['Price'] * df['Quantity']

# 2. تصحيح سعر منتج خاطئ
df.loc[df['Product'] == 'موز', 'Price'] = 3.0

# 3. حذف عمود غير مطلوب
df = df.drop(columns=['Temp_Code'], errors='ignore')  # errors='ignore' يتجاهل الخطأ إذا لم يوجد

# 4. إعادة تسمية الأعمدة لتكون موحدة
df = df.rename(columns=str.capitalize)  # يجعل الحرف الأول كبيرًا

# 5. عرض النتيجة النهائية
print("البيانات النهائية جاهزة للتحليل:\n", df)
```

> ✅ هذا النوع من المعالجة هو ما يحدث يوميًا في الشركات قبل إرسال البيانات إلى التقارير.

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم `inplace=True` بحذر — يُعدّل الأصل ولا يمكن التراجع.
2. ✅ استخدم `errors='ignore'` مع `drop()` لتجنب الأخطاء إذا كان العمود غير موجود.
3. ✅ لا تستخدم `df['column'] = ...` داخل دالة بدون `copy()` — قد تُعدّل نسخة.
4. ✅ استخدم `assign()` في الأنابيب: `df.assign(...).merge(...).groupby(...)`.
5. ✅ تحقق من `df.shape` قبل وبعد الحذف.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `df['new_col'] = ...` و `df.assign()`؟
2. لماذا نستخدم `inplace=True`؟ وما مخاطره؟
3. كيف تحذف صفًا بناءً على شرط؟ (مثلاً: حذف المنتجات التي الكمية = 0)
4. ما الفرق بين `df.drop()` و `del df['col']`؟
5. كيف تُعيد تسمية جميع الأعمدة دفعة واحدة؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| العملية | الطريقة |
|--------|--------|
| إنشاء عمود | `df['new'] = ...` أو `assign()` |
| تعديل قيمة | `df.loc[row, col] = value` |
| حذف عمود | `df.drop(columns=[...])` |
| حذف صف | `df.drop(index=[...])` |
| إعادة التسمية | `df.rename(columns={})` |
| تعديل الأصل | استخدم `inplace=True` أو إعادة التعيين |

# 📘 **الدرس 7  : التعامل مع القيم المفقودة: `dropna()` و `fillna()` و `isnull()`**

## 🔹 **مقدمة: لماذا القيم المفقودة مشكلة؟**

تخيل أنك تحاول حساب **متوسط رواتب الموظفين**، لكن:
- راتب "سارة" غير مسجل
- عمر "علي" ناقص
- مدينة "نورة" مفقودة

إذا تجاهلت هذه القيم، قد تحصل على نتائج:
- غير دقيقة
- مضللة
- تؤثر على قرارات مهمة (مثل التوظيف أو المكافآت)

لذلك، **إدارة القيم المفقودة** (Missing Data) هي واحدة من أهم مهارات تحليل البيانات.

---

## 🔹 **1. ما هي القيم المفقودة؟**

- تُمثل بـ `NaN` (Not a Number) في Pandas
- تحدث بسبب:
  - خطأ في إدخال البيانات
  - عدم توفر المعلومات
  - فشل في جمع البيانات من مصدر ما
- يمكن أن تكون في أي عمود: نص، رقم، تاريخ

---

## 🔹 **2. اكتشاف القيم المفقودة: `isnull()` و `notnull()`**

### ✅ `df.isnull()` — يُرجع `True` إذا كانت القيمة مفقودة

```python
import pandas as pd
import numpy as np

data = {
    'الاسم': ['أحمد', 'سارة', 'علي', 'نورة'],
    'العمر': [25, 30, np.nan, 28],
    'المدينة': ['الرياض', np.nan, 'الدمام', 'مكة'],
    'الراتب': [5000, 7000, 4000, np.nan]
}
df = pd.DataFrame(data)

print(df.isnull())
```

#### 🔍 الناتج:
```
    الاسم   العمر  المدينة   الراتب
0  False  False   False   False
1  False  False    True   False
2  False   True   False   False
3  False  False   False    True
```

> ✅ كل `True` يشير إلى قيمة مفقودة.

---

### ✅ `df.isnull().sum()` — عدد القيم المفقودة لكل عمود

```python
print(df.isnull().sum())
```

#### 🔍 الناتج:
```
الاسم      0
العمر      1
المدينة    1
الراتب      1
dtype: int64
```

> ✅ أداة حيوية لتقييم جودة البيانات.

---

### ✅ `df.isnull().sum().sum()` — العدد الكلي للقيم المفقودة

```python
total_missing = df.isnull().sum().sum()
print(f"إجمالي القيم المفقودة: {total_missing}")  # 3
```

---

## 🔹 **3. حذف الصفوف أو الأعمدة: `dropna()`**

### ✅ الطريقة 1: حذف أي صف يحتوي على قيمة مفقودة

```python
df_clean = df.dropna()
print(df_clean)
```

#### 🔍 الناتج:
```
   الاسم  العمر  المدينة  الراتب
0   أحمد   25.0    الرياض  5000.0
```

> ⚠️ تم حذف 3 صفوف! فقدان كبير للبيانات.

---

### ✅ الطريقة 2: حذف الصفوف التي جميع قيمها مفقودة

```python
df.dropna(how='all')  # نادرًا ما يحدث
```

---

### ✅ الطريقة 3: حذف الصفوف التي تحتوي على قيمة مفقودة في عمود معين

```python
# احذف الصفوف التي العمر فيها مفقود
df.dropna(subset=['العمر'])
```

#### 🔍 الناتج:
```
   الاسم  العمر  المدينة  الراتب
0   أحمد   25.0    الرياض  5000.0
1   سارة   30.0     جدة   7000.0
3   نورة   28.0     مكة     NaN
```

> ✅ فقط الصف 2 (علي) تم حذفه.

---

### ✅ الطريقة 4: حذف الأعمدة التي تحتوي على قيم مفقودة

```python
df.dropna(axis=1)  # axis=1 تعني "العمود"
```

#### 🔍 الناتج:
```
   الاسم
0   أحمد
1   سارة
2   علي
3   نورة
```

> ⚠️ تم حذف 3 أعمدة! فقدان كبير للمعلومات.

---

## 🔹 **4. ملء القيم المفقودة: `fillna()`**

### ✅ الطريقة 1: ملء بالقيمة 0

```python
df_filled = df.fillna(0)
print(df_filled)
```

#### 🔍 الناتج:
```
   الاسم  العمر  المدينة  الراتب
0   أحمد   25.0    الرياض  5000.0
1   سارة   30.0       0  7000.0
2   علي     0.0    الدمام  4000.0
3   نورة   28.0     مكة     0.0
```

> ⚠️ قد لا يكون 0 منطقيًا (مثلاً: عمر 0؟)

---

### ✅ الطريقة 2: ملء بقيمة معينة لكل عمود

```python
values = {'العمر': 25, 'المدينة': 'غير معروفة', 'الراتب': df['الراتب'].mean()}
df_filled = df.fillna(value=values)
print(df_filled)
```

#### 🔍 الناتج:
```
   الاسم  العمر        المدينة  الراتب
0   أحمد   25.0         الرياض  5000.0
1   سارة   30.0    غير معروفة  7000.0
2   علي    25.0        الدمام  4000.0
3   نورة   28.0           مكة  5333.333
```

> ✅ استخدام المتوسط للراتب منطقي.

---

### ✅ الطريقة 3: ملء بالقيمة السابقة أو التالية (للمتسلسلات الزمنية)

```python
# ملء بالقيمة السابقة (ffill)
df.fillna(method='ffill')

# ملء بالقيمة التالية (bfill)
df.fillna(method='bfill')
```

> مفيد في بيانات الأسهم أو الطقس.

---

## 🔹 **5. الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `SettingWithCopyWarning` بعد `fillna()` | التعديل على نسخة | استخدم `.copy()` أو `inplace=True` |
| `fillna()` لا يعمل على عمود نصي | لأن `mean()` لا يُحسب على نص | استخدم نصًا افتراضيًا مثل "مجهول" |
| `dropna()` يحذف بيانات مهمة | لأن القيم المفقودة يمكن استنتاجها | فكّر في "الملء" بدل "الحذف" |
| `np.nan` لا يساوي نفسه | `np.nan == np.nan` → `False` | استخدم `pd.isna(x)` بدل `x == np.nan` |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: احسب جودة البيانات
- أنشئ DataFrame به قيم مفقودة
- احسب نسبة القيم المفقودة لكل عمود

### ✅ التمرين 2: ملء ذكي
املأ عمود "العمر" بالمتوسط، و"المدينة" بـ "غير معروف".

### ✅ التمرين 3: حذف آمن
احذف فقط الصفوف التي **جميع** قيمها مفقودة.

### ✅ التمرين 4: تحليل واقعي
لماذا قد نختار `fillna()` بدل `dropna()` في تحليل الموارد البشرية؟

---

## 🔹 **الربط بالواقع: تحليل قاعدة بيانات موظفين**

### 🎯 الهدف: إعداد البيانات للتحليل الإحصائي

```python
# 1. تقرير جودة البيانات
print("عدد القيم المفقودة:")
print(df.isnull().sum())

# 2. اتخاذ القرار
if df['العمر'].isnull().sum() < 5:
    # ملء بالمتوسط
    df['العمر'] = df['العمر'].fillna(df['العمر'].mean())
else:
    # حذف الصفوف
    df = df.dropna(subset=['العمر'])

# 3. معالجة المدينة
df['المدينة'] = df['المدينة'].fillna('غير معروفة')

# 4. حساب متوسط الراتب بعد المعالجة
avg_salary = df['الراتب'].mean()
print(f"متوسط الراتب بعد المعالجة: {avg_salary:,.2f} ريال")
```

> ✅ هذا الأسلوب يُستخدم في المؤسسات لضمان دقة التقارير.

---

## 🔹 **نصائح احترافية**

1. ✅ لا تحذف البيانات بسرعة — فكّر في "الاستنتاج" أولًا.
2. ✅ استخدم `fillna()` مع قيم منطقية (متوسط، وسط، أحدث قيمة).
3. ✅ تجنب ملء القيم المفقودة بـ 0 إلا إذا كان ذلك منطقيًا.
4. ✅ استخدم `inplace=True` بحذر: `df.fillna(0, inplace=True)`.
5. ✅ وثّق كل خطوة: "تم ملء العمر بالمتوسط بسبب نقص 2% من البيانات".

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `isnull()` و `notnull()`؟
2. متى نستخدم `dropna()` ومتى نستخدم `fillna()`؟
3. لماذا `np.nan == np.nan` يُرجع `False`؟
4. ما معنى `axis=0` و `axis=1` في `dropna()`؟
5. كيف تملأ القيم المفقودة في عمود نصي؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الأداة | الوظيفة |
|-------|--------|
| `isnull()` | كشف القيم المفقودة |
| `isnull().sum()` | عدد القيم المفقودة لكل عمود |
| `dropna()` | حذف الصفوف/الأعمدة التي بها قيم مفقودة |
| `fillna()` | ملء القيم المفقودة بقيمة معينة |
| `method='ffill'` | ملء بالقيمة السابقة |
| `subset=[...]` | تطبيق على عمود معين فقط |

# 📘 **الدرس 8  : التجميع باستخدام `groupby()`: كيفية حساب المتوسط، المجموع، عدد التكرارات حسب فئات معينة**

## 🔹 **مقدمة: لماذا نستخدم `groupby()`؟**

تخيل أنك مدير مبيعات، ولديك جدول يحتوي على 10,000 صف من عمليات البيع.  
تريد الإجابة على أسئلة مثل:
- ما **إجمالي المبيعات لكل فئة منتج**؟
- ما **متوسط سعر المنتج في كل مدينة**؟
- كم **عدد العملاء في كل فرع**؟

هنا تأتي أهمية **`groupby()`** — وهي واحدة من أقوى أدوات Pandas.

تُستخدم `groupby()` لـ:
> **تقسيم البيانات إلى مجموعات، ثم تطبيق دالة تجميع (مثل المجموع أو المتوسط) على كل مجموعة.**

---

## 🔹 **1. المبدأ الأساسي لـ `groupby()`**

العملية تشبه:
1. **تقسيم** البيانات إلى مجموعات (مثلاً: حسب "الفئة")
2. **تطبيق** دالة (مثل `sum` أو `mean`)
3. **دمج** النتائج في جدول جديد

### ✅ الصيغة العامة:
```python
df.groupby('العمود_الذي_نجمع_به')['العمود_المراد_تجميعه'].دالة_تجميع()
```

---

## 🔹 **2. أمثلة عملية**

### 📌 المثال 1: إجمالي المبيعات لكل فئة منتج

```python
import pandas as pd
import numpy as np

data = {
    'المنتج': ['تفاح', 'موز', 'لابتوب', 'سماعة', 'حليب', 'شاشة'],
    'الفئة': ['فواكه', 'فواكه', 'إلكترونيات', 'إلكترونيات', 'ألبان', 'إلكترونيات'],
    'السعر': [3.5, 2.0, 2500, 150, 8.0, 800],
    'الكمية': [50, 30, 5, 20, 40, 3],
    'المدينة': ['الرياض', 'جدة', 'الرياض', 'جدة', 'الدمام', 'الرياض']
}

df = pd.DataFrame(data)
df['الإجمالي'] = df['السعر'] * df['الكمية']

# إجمالي المبيعات لكل فئة
total_by_category = df.groupby('الفئة')['الإجمالي'].sum()
print(total_by_category)
```

#### 🔍 الناتج:
```
الفئة
ألبان           320.0
إلكترونيات   17800.0
فواكه          235.0
Name: الإجمالي, dtype: float64
```

> ✅ الفئات الإلكترونية هي الأعلى مبيعًا.

---

### 📌 المثال 2: متوسط السعر لكل فئة

```python
avg_price = df.groupby('الفئة')['السعر'].mean()
print(avg_price)
```

#### 🔍 الناتج:
```
الفئة
ألبان           8.0
إلكترونيات  1116.666667
فواكه          2.75
Name: السعر, dtype: float64
```

> ✅ متوسط سعر الإلكترونيات مرتفع جدًا.

---

### 📌 المثال 3: عدد المنتجات في كل فئة

```python
count_by_category = df.groupby('الفئة').size()
print(count_by_category)
```

#### 🔍 الناتج:
```
الفئة
ألبان           1
إلكترونيات     3
فواكه          2
dtype: int64
```

> ✅ `size()` يحسب عدد الصفوف في كل مجموعة.

---

### 📌 المثال 4: استخدام `count()` بدل `size()`

```python
count_values = df.groupby('الفئة')['المنتج'].count()
```

> ✅ الفرق: `count()` لا يحسب القيم المفقودة، بينما `size()` يحسب كل الصفوف.

---

## 🔹 **3. تجميع متعدد الأعمدة**

### 📌 المثال 5: مجموع وعدد وحدات المبيعات لكل مدينة

```python
summary = df.groupby('المدينة').agg({
    'الكمية': ['sum', 'mean'],
    'الإجمالي': 'sum',
    'المنتج': 'count'
})
print(summary)
```

#### 🔍 الناتج:
```
           الكمية            الإجمالي  المنتج
              sum  mean         sum   count
المدينة                                     
الدمام         40  40.0         320        1
الرياض        58  19.333    13875.0        3
جدة           50  25.0      3960.0        2
```

> ✅ استخدام `agg()` يسمح بتطبيق دوال مختلفة على أعمدة مختلفة.

---

## 🔹 **4. التجميع حسب أكثر من عمود**

### 📌 المثال 6: متوسط السعر لكل فئة في كل مدينة

```python
multi_group = df.groupby(['المدينة', 'الفئة'])['السعر'].mean()
print(multi_group)
```

#### 🔍 الناتج:
```
المدينة  الفئة       
الدمام    ألبان           8.0
الرياض   إلكترونيات  1650.0
         فواكه          3.5
جدة      إلكترونيات   150.0
         فواكه          2.0
Name: السعر, dtype: float64
```

> ✅ يمكنك التجميع حسب أكثر من عمود باستخدام قائمة.

---

## 🔹 **5. الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `KeyError` | اسم عمود غير موجود | تحقق من `df.columns` |
| `No numeric types to aggregate` | تحاول تطبيق `sum` على عمود نصي | تأكد من نوع البيانات |
| الناتج غير مرتب | لا توجد ترتيبات | استخدم `.sort_values()` لاحقًا |
| `groupby` لا يُظهر النتائج | لأن الناتج Series | استخدم `.reset_index()` لتحويله إلى DataFrame |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: مبيعات كل مدينة
احسب **إجمالي المبيعات لكل مدينة**.

### ✅ التمرين 2: متوسط الكمية
احسب **متوسط الكمية المباعة لكل فئة منتج**.

### ✅ التمرين 3: عدد المنتجات
كم عدد المنتجات في كل فئة؟ استخدم `size()` و `count()`، وقارن النتائج.

### ✅ التمرين 4: تجميع متقدم
أنشئ تقريرًا يُظهر:
- المجموع والحد الأقصى للسعر
- متوسط الكمية
لكل فئة منتج.

---

## 🔹 **الربط بالواقع: تقرير مبيعات شهري**

### 🎯 الهدف: إعداد تقرير إداري

```python
# 1. إجمالي المبيعات لكل فئة
sales_by_category = df.groupby('الفئة')['الإجمالي'].sum()

# 2. متوسط سعر البيع لكل مدينة
avg_price_city = df.groupby('المدينة')['السعر'].mean()

# 3. عدد المنتجات المباعة لكل فرع
products_per_city = df.groupby('المدينة').size()

# 4. تقرير نهائي
report = pd.DataFrame({
    'إجمالي المبيعات': df.groupby('المدينة')['الإجمالي'].sum(),
    'متوسط السعر': df.groupby('المدينة')['السعر'].mean(),
    'عدد المنتجات': df.groupby('المدينة').size()
}).round(2)

print("📊 تقرير أداء الفروع:")
print(report)
```

#### 🔍 الناتج:
```
📊 تقرير أداء الفروع:
         إجمالي المبيعات  متوسط السعر  عدد المنتجات
المدينة                                     
الدمام           320.0          8.0             1
الرياض         13875.0       1653.5             3
جدة           3960.0        152.0             2
```

> ✅ هذا التقرير يمكن عرضه في اجتماعات الإدارة.

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم `reset_index()` لتحويل الناتج إلى DataFrame قابل للحفظ.
2. ✅ استخدم `round(2)` لتقريب الأرقام.
3. ✅ تجنب `groupby` على أعمدة بها كثير من القيم الفريدة (مثل الأسماء).
4. ✅ استخدم `agg()` عند الحاجة إلى دوال متعددة.
5. ✅ تحقق من أنواع البيانات قبل التجميع.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `sum()` و `count()` في `groupby()`؟
2. لماذا نستخدم `reset_index()` بعد `groupby()`؟
3. كيف تُرجع متوسط عمودين معًا في `groupby()`؟
4. ما معنى `.agg()`؟
5. كيف تُرجع أعلى قيمة في كل مجموعة؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الدالة | الوظيفة |
|-------|--------|
| `groupby('col')` | التجميع حسب عمود |
| `.sum()` | المجموع |
| `.mean()` | المتوسط |
| `.count()` | عدد القيم غير المفقودة |
| `.size()` | عدد الصفوف (بما في ذلك المفقودة) |
| `.agg()` | تطبيق دوال متعددة |
| `reset_index()` | تحويل الناتج إلى DataFrame |


# 📘 **الدرس 9  : ترتيب البيانات باستخدام `sort_values()`**

## 🔹 **مقدمة: لماذا نحتاج إلى الترتيب؟**

تخيل أنك تنظر إلى قائمة مبيعات غير مرتبة:
- منتجات بأسعار عشوائية
- تواريخ غير منظمة
- رواتب موظفين غير مصنفة

من الصعب جدًا:
- اكتشاف أعلى راتب
- معرفة أحدث عملية بيع
- تحديد أفضل 5 منتجات مبيعًا

لهذا، **ترتيب البيانات** هو خطوة أساسية في أي تحليل.  
والأداة الرئيسية في Pandas لذلك هي:  
> ✅ `sort_values()`

---

## 🔹 **1. الترتيب الأساسي: ترتيب عمود واحد**

### ✅ الطريقة: `df.sort_values('العمود')`

```python
import pandas as pd

data = {
    'المنتج': ['تفاح', 'موز', 'لابتوب', 'سماعة'],
    'السعر': [3.5, 2.0, 2500, 150],
    'الكمية': [50, 30, 5, 20]
}
df = pd.DataFrame(data)

# ترتيب حسب السعر (تصاعديًا - الافتراضي)
sorted_df = df.sort_values('السعر')
print(sorted_df)
```

#### 🔍 الناتج:
```
   المنتج  السعر  الكمية
1     موز    2.0     30
0    تفاح    3.5     50
3   سماعة  150.0     20
2   لابتوب 2500.0      5
```

> ✅ تم ترتيب الصفوف من الأقل سعرًا إلى الأعلى.

---

## 🔹 **2. الترتيب التنازلي: `ascending=False`**

```python
# ترتيب حسب السعر من الأعلى إلى الأدنى
sorted_desc = df.sort_values('السعر', ascending=False)
print(sorted_desc)
```

#### 🔍 الناتج:
```
   المنتج    السعر  الكمية
2   لابتوب  2500.0      5
3   سماعة   150.0     20
0    تفاح     3.5     50
1     موز     2.0     30
```

> ✅ مفيد لعرض "أعلى 5 مبيعات" أو "أعلى الرواتب".

---

## 🔹 **3. الترتيب حسب أكثر من عمود**

### ✅ الطريقة: تمرير قائمة من الأعمدة

```python
# ترتيب حسب الفئة، ثم حسب السعر داخل كل فئة
data['الفئة'] = ['فواكه', 'فواكه', 'إلكترونيات', 'إلكترونيات']
df = pd.DataFrame(data)

sorted_multi = df.sort_values(['الفئة', 'السعر'], ascending=[True, False])
print(sorted_multi)
```

#### 🔍 الناتج:
```
   المنتج       الفئة  السعر  الكمية
3   سماعة  إلكترونيات  150.0     20
2   لابتوب  إلكترونيات 2500.0      5
0    تفاح        فواكه    3.5     50
1     موز        فواكه    2.0     30
```

> ✅ أولاً: تُرتب الفئات (إلكترونيات أولًا، ثم فواكه)  
> ثانيًا: داخل كل فئة، يُرتب السعر تنازليًا.

---

## 🔹 **4. الترتيب حسب الفهرس (Index): `sort_index()`**

مفيد عندما تريد إعادة ترتيب الجدول حسب التسلسل الأصلي بعد عملية فلترة أو إعادة ترتيب.

```python
# افترض أنك فلترت وحذفت بعض الصفوف
filtered = df[df['السعر'] > 100]
# الفهارس أصبحت: 2, 3

# إعادة الترتيب حسب الفهرس
sorted_by_index = filtered.sort_index()
```

> ✅ يُستخدم غالبًا بعد `reset_index()`.

---

## 🔹 **5. الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `KeyError` | اسم عمود غير موجود | تحقق من `df.columns` |
| لا يتغير الجدول الأصلي | لأن `sort_values()` لا يُعدّل الأصل | استخدم `inplace=True` أو احفظ الناتج |
| الترتيب غير دقيق على النصوص | لأن الحروف الكبيرة تُرتب قبل الصغيرة | استخدم `.str.lower()` قبل الترتيب |
| الترتيب على عمود به `NaN` | القيم المفقودة تظهر في النهاية | استخدم `na_position='first'` إذا أردتها في البداية |

---

## 🔹 **6. التحكم في وضع القيم المفقودة: `na_position`**

```python
data_with_nan = {
    'الاسم': ['أحمد', 'سارة', 'علي'],
    'الراتب': [5000, np.nan, 4000]
}
df_nan = pd.DataFrame(data_with_nan)

# وضع القيم المفقودة في البداية
sorted_nan = df_nan.sort_values('الراتب', na_position='first')
print(sorted_nan)
```

#### 🔍 الناتج:
```
   الاسم  الراتب
1   سارة    NaN
2   علي  4000.0
0   أحمد  5000.0
```

> ✅ مفيد عندما تريد اكتشاف القيم الناقصة أولًا.

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: ترتيب تصاعدي
رتب الجدول حسب "الكمية" من الأقل إلى الأكثر.

### ✅ التمرين 2: ترتيب متعدد
رتب الجدول حسب "الفئة" (تصاعدي)، ثم "السعر" (تنازلي).

### ✅ التمرين 3: قمة المبيعات
أظهر أفضل 3 منتجات من حيث "الإجمالي" (بعد حسابه).

### ✅ التمرين 4: ترتيب بالفهرس
بعد فلترة الجدول، كيف تُعيد ترتيب الفهارس؟

---

## 🔹 **الربط بالواقع: قائمة أفضل الموظفين**

### 🎯 الهدف: إعداد تقرير مكافآت

```python
# بيانات الموظفين
employees = pd.DataFrame({
    'الاسم': ['أحمد', 'سارة', 'علي', 'نورة', 'خالد'],
    'القسم': ['مبيعات', 'مبيعات', 'تسويق', 'مبيعات', 'تسويق'],
    'الأداء': [88, 94, 76, 91, 82],
    'الراتب': [5000, 7000, 4000, 6000, 4500]
})

# ترتيب حسب القسم، ثم حسب الأداء (من الأعلى)
top_performers = employees.sort_values(['القسم', 'الأداء'], ascending=[True, False])

print("🏆 أفضل الموظفين حسب القسم:")
print(top_performers)
```

#### 🔍 الناتج:
```
   الاسم   القسم  الأداء  الراتب
1   سارة  مبيعات     94   7000
3   نورة  مبيعات     91   6000
0   أحمد  مبيعات     88   5000
4   خالد  تسويق     82   4500
2   علي   تسويق     76   4000
```

> ✅ هذا التقرير يُستخدم في توزيع المكافآت.

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم `inplace=True` إذا كنت لا تحتاج النسخة الأصلية:  
   `df.sort_values('السعر', inplace=True)`
2. ✅ استخدم `head(n)` بعد الترتيب للحصول على "أفضل n عنصر".
3. ✅ تجنب الترتيب على أعمدة نصية بدون تحويلها إلى صغيرة:  
   `df.sort_values(df['الاسم'].str.lower())`
4. ✅ استخدم `reset_index(drop=True)` بعد الترتيب إذا أردت فهرسًا جديدًا.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `sort_values()` و `sort_index()`؟
2. كيف تُرتب تنازليًا؟
3. ما معنى `na_position='first'`؟
4. كيف تُرتب حسب عمودين معًا؟
5. لماذا لا يتغير الجدول الأصلي عند استخدام `sort_values()`؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الدالة | الوظيفة |
|-------|--------|
| `sort_values('col')` | ترتيب حسب عمود |
| `ascending=False` | ترتيب تنازلي |
| `sort_values(['A','B'])` | ترتيب متعدد |
| `na_position='first'` | وضع القيم المفقودة في البداية |
| `sort_index()` | ترتيب حسب الفهرس |
| `inplace=True` | تعديل الجدول الأصلي |


# 📘 **الدرس 10  : دمج وربط البيانات باستخدام `merge` و `concat`**

## 🔹 **مقدمة: لماذا نحتاج إلى دمج البيانات؟**

في العالم الحقيقي، **نادرًا ما تكون البيانات في جدول واحد**.  
غالبًا ما تكون مقسمة على:
- ملفات منفصلة (مبيعات يناير، فبراير، مارس)
- جداول مختلفة (بيانات العملاء، بيانات الطلبات)
- مصادر متعددة (قاعدة بيانات، ملف إكسل، API)

لذلك، نحتاج إلى أدوات لـ:
- **دمج الجداول رأسيًا** (إضافة صفوف): مثل دمج بيانات 3 أشهر
- **دمج الجداول أفقيًا** (إضافة أعمدة): مثل ربط العميل بطلبه

هنا تأتي أهمية:
> ✅ `pd.concat()` للدمج العام  
> ✅ `pd.merge()` للربط بالعلاقة (مثل JOIN في SQL)

---

## 🔹 **1. الدمج الرأسي: `pd.concat()`**

يُستخدم لـ **تجميع جداول فوق بعضها** (مثل دمج عدة ملفات).

### 📌 المثال 1: دمج 3 جداول مبيعات شهرية

```python
import pandas as pd

jan = pd.DataFrame({
    'المنتج': ['تفاح', 'موز'],
    'الكمية': [100, 150],
    'الشهر': 'يناير'
})

feb = pd.DataFrame({
    'المنتج': ['تفاح', 'حليب'],
    'الكمية': [120, 80],
    'الشهر': 'فبراير'
})

mar = pd.DataFrame({
    'المنتج': ['موز', 'لابتوب'],
    'الكمية': [200, 5],
    'الشهر': 'مارس'
})

# دمج الجداول رأسيًا
total_sales = pd.concat([jan, feb, mar], ignore_index=True)
print(total_sales)
```

#### 🔍 الناتج:
```
   المنتج  الكمية    الشهر
0    تفاح     100    يناير
1     موز     150    يناير
2    تفاح     120   فبراير
3    حليب      80   فبراير
4     موز     200    مارس
5   لابتوب      5    مارس
```

> ✅ `ignore_index=True` لإعادة ترقيم الصفوف من 0.

---

### ✅ خيارات مهمة في `concat()`

| الخيار | الوظيفة |
|--------|--------|
| `axis=0` | دمج رأسي (الافتراضي) |
| `axis=1` | دمج أفقي (جنبًا إلى جنب) |
| `ignore_index=True` | تجاهل الفهارس القديمة |
| `sort=False` | عدم فرز الأعمدة تلقائيًا |

---

### 📌 المثال 2: دمج أفقي (نادر الاستخدام)

```python
names = pd.DataFrame({'الاسم': ['أحمد', 'سارة']})
ages = pd.DataFrame({'العمر': [25, 30]})

combined = pd.concat([names, ages], axis=1)
print(combined)
```

#### 🔍 الناتج:
```
   الاسم  العمر
0   أحمد     25
1   سارة     30
```

> ⚠️ يجب أن يكون عدد الصفوف متطابقًا.

---

## 🔹 **2. الربط بالعلاقة: `pd.merge()` (مثل JOIN في SQL)**

يُستخدم لربط جدولين بناءً على **عمود مشترك** (مفتاح).

### 📌 المثال 3: ربط طلبات بالعملاء

```python
# جدول العملاء
customers = pd.DataFrame({
    'ID': [1, 2, 3],
    'الاسم': ['أحمد', 'سارة', 'علي'],
    'المدينة': ['الرياض', 'جدة', 'الدمام']
})

# جدول الطلبات
orders = pd.DataFrame({
    'OrderID': [101, 102, 103],
    'ID': [1, 2, 1],
    'المنتج': ['لابتوب', 'موز', 'تفاح'],
    'السعر': [2500, 2.0, 3.5]
})

# ربط الطلبات باسم العميل
merged = pd.merge(orders, customers, on='ID')
print(merged)
```

#### 🔍 الناتج:
```
   OrderID  ID  المنتج  السعر  الاسم  المدينة
0      101   1  لابتوب  2500.0  أحمد   الرياض
1      102   2    موز     2.0  سارة     جدة
2      103   1   تفاح     3.5  أحمد   الرياض
```

> ✅ تم إضافة اسم ومكان العميل لكل طلب.

---

## 🔹 **3. أنواع الـ `merge` (joins)**

| النوع | الوصف | الاستخدام |
|------|------|----------|
| `inner` (الافتراضي) | يُرجع الصفوف المشتركة فقط | `how='inner'` |
| `outer` | يُرجع كل الصفوف، inclusive | `how='outer'` |
| `left` | يُرجع كل صفوف الجدول الأيسر | `how='left'` |
| `right` | يُرجع كل صفوف الجدول الأيمن | `how='right'` |

### 📌 المثال 4: `left join` – إظهار جميع الطلبات، حتى لو لم يُعرف العميل

```python
# افترض أن هناك طلبًا لـ ID=4 (غير موجود في العملاء)
orders_new = pd.DataFrame({
    'OrderID': [101, 102, 104],
    'ID': [1, 2, 4],
    'المنتج': ['لابتوب', 'موز', 'شاشة']
})

left_merge = pd.merge(orders_new, customers, on='ID', how='left')
print(left_merge)
```

#### 🔍 الناتج:
```
   OrderID  ID  المنتج  الاسم  المدينة
0      101   1  لابتوب   أحمد   الرياض
1      102   2    موز   سارة     جدة
2      104   4  شاشة   NaN     NaN
```

> ✅ مفيد للكشف عن الطلبات بدون عميل.

---

## 🔹 **4. الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `KeyError` في `on=` | العمود غير موجود في أحد الجداول | تحقق من `df.columns` |
| `concat()` يُكرر الفهارس | لأن الفهارس الأصلية تم الحفاظ عليها | استخدم `ignore_index=True` |
| `merge()` يُنتج صفوفًا أكثر | بسبب تكرار المفاتيح (مثلاً: عميل له عدة طلبات) | هذا طبيعي، وليس خطأ |
| دمج أفقي بـ `concat` يُنتج `NaN` | لأن عدد الصفوف غير متساوٍ | تأكد من تطابق الأحجام |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: دمج شهري
أنشئ جدولين لشهر يناير وفبراير، ثم ادمجهما باستخدام `concat`.

### ✅ التمرين 2: ربط بيانات
لديك جدول "المنتجات" وجدول "المخزون"، اربطهما بـ `merge` باستخدام "المنتج".

### ✅ التمرين 3: left join
استخدم `how='left'` لعرض جميع الطلبات، حتى التي لا يُعرف فيها العميل.

### ✅ التمرين 4: دمج أفقي
ادمج عمود "الراتب" مع جدول "الموظفين" أفقيًا.

---

## 🔹 **الربط بالواقع: نظام مبيعات متكامل**

### 🎯 الهدف: بناء تقرير مبيعات شامل

```python
# 1. دمج بيانات 3 أشهر
q1_sales = pd.concat([jan, feb, mar], ignore_index=True)

# 2. ربط الطلبات بالعملاء
detailed_orders = pd.merge(orders, customers, on='ID', how='left')

# 3. حساب الإجمالي
detailed_orders['الإجمالي'] = detailed_orders['الكمية'] * detailed_orders['السعر']

# 4. تقرير نهائي
final_report = detailed_orders[['الاسم', 'المدينة', 'المنتج', 'الإجمالي']]
print("📌 تقرير المبيعات التفصيلي:")
print(final_report)
```

> ✅ هذا هو الشكل النهائي لتحليل البيانات في الشركات.

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم `merge()` عندما يكون هناك علاقة منطقية (مفتاح مشترك).
2. ✅ استخدم `concat()` لدمج بيانات متجانسة (مثل بيانات شهرية).
3. ✅ تحقق من أنواع البيانات في العمود المشترك (مثلاً: `ID` يجب أن يكون نفس النوع).
4. ✅ استخدم `validate='one_to_many'` للتأكد من نوع العلاقة.
5. ✅ وثّق نوع الـ join المستخدم في التقرير.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `concat` و `merge`؟
2. متى نستخدم `how='left'`؟
3. ما معنى `ignore_index=True` في `concat`؟
4. كيف تدمج جدولين ليس لهما نفس الأعمدة؟
5. ماذا يحدث إذا كان العمود المشترك به تكرار؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الأداة | الاستخدام |
|-------|----------|
| `pd.concat()` | دمج جداول رأسيًا أو أفقيًا |
| `pd.merge()` | ربط جدولين بعمود مشترك |
| `how='inner'` | فقط الصفوف المشتركة |
| `how='left'` | كل صفوف الجدول الأيسر |
| `on='col'` | العمود المشترك |
| `ignore_index=True` | إعادة ترقيم الصفوف |


# 📘 **الدرس 11  : التعامل مع الأعمدة الزمنية: `pd.to_datetime()` و `.dt` و تصفية التواريخ**

## 🔹 **مقدمة: لماذا التواريخ مهمة في تحليل البيانات؟**

في أي مشروع تحليل بيانات — سواء في **المبيعات، التداول، أو الموارد البشرية** — فإن **الزمن** هو بُعد حاسم.

أسئلة مثل:
- ما إجمالي المبيعات في **الربع الأول**؟
- متى كان **أعلى نشاط تداول**؟
- كم عدد الموظفين الذين انضموا في **الشهر الماضي**؟

تتطلب جميعها **فهمًا دقيقًا للتواريخ**.

لهذا، Pandas توفر أدوات قوية جدًا للتعامل مع البيانات الزمنية.

---

## 🔹 **1. تحويل النص إلى تاريخ: `pd.to_datetime()`**

غالبًا ما تكون التواريخ في الملفات كـ **نصوص** (مثل `'2023-01-01'`)، ويجب تحويلها إلى نوع `datetime` لتطبيق العمليات الزمنية.

### 📌 المثال 1: تحويل عمود نصي إلى تاريخ

```python
import pandas as pd

data = {
    'التاريخ': ['2023-01-01', '2023-01-02', '2023-01-03', '04/01/2023'],
    'المنتج': ['تفاح', 'موز', 'حليب', 'لابتوب'],
    'الإجمالي': [350, 300, 400, 2500]
}
df = pd.DataFrame(data)

# تحويل العمود إلى datetime
df['التاريخ'] = pd.to_datetime(df['التاريخ'])
print(df.dtypes)
```

#### 🔍 الناتج:
```
التاريخ      datetime64[ns]
المنتج              object
الإجمالي            float64
dtype: object
```

> ✅ الآن يمكننا التعامل مع العمود كـ "تاريخ".

---

### ✅ دعم تنسيقات متعددة تلقائيًا

`pd.to_datetime()` يفهم تلقائيًا:
- `'2023-01-01'`
- `'01/01/2023'`
- `'Jan 1, 2023'`
- `'01-Jan-2023'`

> ⚠️ لكن يُفضل توحيد التنسيق.

---

### ✅ تحديد التنسيق يدويًا (لتحسين الأداء)

إذا كنت تعرف التنسيق، استخدم `format=`:

```python
df['التاريخ'] = pd.to_datetime(df['التاريخ'], format='%d/%m/%Y')
```

> ✅ أسرع وأكثر دقة.

---

## 🔹 **2. استخراج مكونات التاريخ: `.dt`**

بمجرد أن يصبح العمود من نوع `datetime`، يمكنك استخدام `.dt` لاستخراج:
- السنة
- الشهر
- اليوم
- اليوم من الأسبوع
- الربع
- وغيرها

### 📌 المثال 2: استخراج السنة والشهر

```python
df['السنة'] = df['التاريخ'].dt.year
df['الشهر'] = df['التاريخ'].dt.month
df['اليوم'] = df['التاريخ'].dt.day
df['اليوم_من_الأسبوع'] = df['التاريخ'].dt.day_name()
df['الربع'] = df['التاريخ'].dt.quarter

print(df)
```

#### 🔍 الناتج:
```
    التاريخ  المنتج  الإجمالي  السنة  الشهر  اليوم  اليوم_من_الأسبوع  الربع
0 2023-01-01   تفاح     350.0  2023      1      1         Monday      1
1 2023-01-02    موز     300.0  2023      1      2        Tuesday      1
2 2023-01-03   حليب     400.0  2023      1      3      Wednesday      1
3 2023-01-04  لابتوب    2500.0  2023      1      4       Thursday      1
```

> ✅ الآن يمكن التجميع حسب الشهر أو اليوم.

---

## 🔹 **3. تصفية البيانات حسب التاريخ**

### 📌 المثال 3: المبيعات في يناير فقط

```python
jan_sales = df[df['التاريخ'].dt.month == 1]
print(jan_sales)
```

---

### 📌 المثال 4: المبيعات بين تاريخين

```python
start = '2023-01-01'
end = '2023-01-03'

filtered = df[(df['التاريخ'] >= start) & (df['التاريخ'] <= end)]
print(filtered)
```

> ✅ نفس الفلترة الشرطية، لكن مع تواريخ.

---

### 📌 المثال 5: استخدام `between()` مع التواريخ

```python
filtered = df[df['التاريخ'].between('2023-01-01', '2023-01-02')]
```

---

## 🔹 **4. التواريخ الخاصة: `pd.Timestamp` و `pd.Timedelta`**

### ✅ `pd.Timestamp` — كائن تاريخ دقيق

```python
today = pd.Timestamp('2023-10-01')
print(today.year, today.month)
```

---

### ✅ `pd.Timedelta` — فرق زمني

```python
# إضافة 7 أيام
df['تاريخ_التسليم'] = df['التاريخ'] + pd.Timedelta(days=7)
```

---

## 🔹 **5. الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `OutOfBoundsDatetime` | تاريخ خارج النطاق (مثلاً: 10000) | تحقق من البيانات |
| `TypeError` عند `.dt` | العمود ليس من نوع `datetime` | تأكد من `pd.to_datetime()` |
| `SettingWithCopyWarning` | تعديل على نسخة | استخدم `.copy()` أو `loc` |
| التاريخ يُعرض كـ `2023-01-01 00:00:00` | لأن `datetime` يحتوي على وقت | استخدم `.dt.date` لعرض التاريخ فقط |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: تحويل تواريخ
لديك عمود `'2023/01/01'`, `'02-01-2023'` — حوله إلى `datetime`.

### ✅ التمرين 2: استخراج الشهر
أنشئ عمودًا جديدًا باسم "اسم الشهر" (يناير، فبراير...).

### ✅ التمرين 3: تصفية أسبوعية
أظهر المبيعات من يوم الإثنين إلى الأربعاء فقط.

### ✅ التمرين 4: حساب الفرق
احسب عدد الأيام بين "التاريخ" و"تاريخ التسليم".

---

## 🔹 **الربط بالواقع: تحليل مبيعات ربع سنوية**

### 🎯 الهدف: إعداد تقرير زمني

```python
# 1. تحويل التاريخ
df['التاريخ'] = pd.to_datetime(df['التاريخ'])

# 2. استخراج الربع
df['الربع'] = df['التاريخ'].dt.quarter

# 3. تجميع المبيعات حسب الربع
quarterly_sales = df.groupby('الربع')['الإجمالي'].sum()

print("📈 المبيعات حسب الربع:")
print(quarterly_sales)
```

#### 🔍 الناتج:
```
📈 المبيعات حسب الربع:
الربع
1    3550.0
Name: الإجمالي, dtype: float64
```

> ✅ هذا التقرير يُستخدم في اجتماعات الإدارة.

---

## 🔹 **نصائح احترافية**

1. ✅ دائمًا حول الأعمدة الزمنية إلى `datetime` في بداية التحليل.
2. ✅ استخدم `.dt.strftime('%B')` للحصول على اسم الشهر بالعربي أو الإنجليزي.
3. ✅ تجنب تخزين التواريخ كنصوص — يُصعّب التحليل.
4. ✅ استخدم `df['التاريخ'].min()` و `.max()` لمعرفة مدى البيانات الزمنية.
5. ✅ احفظ التواريخ بتنسيق قياسي: `YYYY-MM-DD`.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `pd.to_datetime()` و `.dt`؟
2. كيف تُرجع اسم الشهر من التاريخ؟
3. ما معنى `pd.Timedelta(days=1)`؟
4. كيف تُرجع المبيعات في الأسبوع الأول من الشهر؟
5. لماذا يجب تحويل النص إلى `datetime` قبل التحليل؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الأداة | الوظيفة |
|-------|--------|
| `pd.to_datetime()` | تحويل نص إلى تاريخ |
| `.dt.year` | استخراج السنة |
| `.dt.month` | استخراج الشهر |
| `.dt.day_name()` | اسم اليوم |
| `.dt.quarter` | الربع |
| `.between()` | تصفية نطاق تواريخ |
| `pd.Timedelta` | إضافة/طرح أيام |


# 📘 **الدرس 12  : حفظ البيانات إلى ملفات باستخدام `to_csv` و `to_excel`**

## 🔹 **مقدمة: لماذا نحفظ البيانات؟**

بعد أن تُحلّل البيانات، وتُنظّف، وتُجمّع، وتُرتّب —  
يجب أن **تحفظ النتائج** لـ:
- مشاركتها مع الفريق
- إرسالها إلى الإدارة
- استخدامها في تقارير إكسل
- حفظها كنسخة احتياطية
- إدخالها في أنظمة أخرى

لهذا، Pandas توفر أدوات بسيطة وقوية لحفظ البيانات إلى ملفات.

---

## 🔹 **1. حفظ إلى ملف CSV: `to_csv()`**

### ✅ الطريقة الأساسية

```python
import pandas as pd

data = {
    'المنتج': ['تفاح', 'موز', 'لابتوب'],
    'السعر': [3.5, 2.0, 2500],
    'الكمية': [50, 30, 5],
    'الإجمالي': [175.0, 60.0, 12500.0]
}
df = pd.DataFrame(data)

# حفظ إلى ملف CSV
df.to_csv('mohamad_sales.csv')
```

> ✅ تم إنشاء ملف باسم `mohamad_sales.csv` في المجلد الحالي.

---

### ✅ خيارات مهمة في `to_csv()`

| الخيار | الوظيفة | مثال |
|--------|--------|------|
| `index=False` | عدم حفظ الفهرس (مهم!) | `to_csv('file.csv', index=False)` |
| `encoding='utf-8'` | دعم اللغة العربية | `encoding='utf-8-sig'` |
| `sep=';'` | تغيير الفاصل | مفيد في بعض البرامج |
| `columns=[...]` | حفظ أعمدة محددة فقط | `columns=['المنتج', 'الإجمالي']` |
| `mode='a'` | إضافة إلى الملف (append) | لدمج بيانات جديدة |

### 📌 المثال 1: حفظ بدون فهرس وبدعم عربي

```python
df.to_csv('sales_arabic.csv', index=False, encoding='utf-8-sig')
```

> ✅ ضروري لعرض النصوص العربية بشكل صحيح في إكسل.

---

### 📌 المثال 2: إضافة بيانات إلى ملف موجود

```python
# افترض أنك تريد إضافة شهر جديد
new_month = pd.DataFrame({'المنتج': ['شاشة'], 'السعر': [800], 'الكمية': [3], 'الإجمالي': [2400]})

# حفظ في وضع "إضافة"
new_month.to_csv('sales_arabic.csv', mode='a', header=False, index=False, encoding='utf-8-sig')
```

> ✅ `header=False` لتجنب تكرار العناوين.

---

## 🔹 **2. حفظ إلى ملف إكسل: `to_excel()`**

### ✅ الطريقة الأساسية

```python
df.to_excel('sales_report.xlsx', index=False)
```

> ⚠️ تحتاج تثبيت `openpyxl`:  
> ```bash
> pip install openpyxl
> ```

---

### ✅ خيارات مهمة في `to_excel()`

| الخيار | الوظيفة |
|--------|--------|
| `sheet_name='ورقة1'` | تسمية الورقة |
| `index=False` | عدم حفظ الفهرس |
| `encoding='utf-8'` | لا يدعمه `to_excel` مباشرة — لكن الملف يدعم العربية تلقائيًا |
| `startrow` و `startcol` | البدء من صف وعمود معين |
| `float_format='%.2f'` | تنسيق الأرقام |

### 📌 المثال 3: حفظ إلى ورقة محددة

```python
with pd.ExcelWriter('quarterly_report.xlsx') as writer:
    df.to_excel(writer, sheet_name='يناير', index=False)
    df.to_excel(writer, sheet_name='فبراير', index=False)
```

> ✅ `ExcelWriter` يسمح بحفظ عدة أوراق في ملف واحد.

---

### 📌 المثال 4: تنسيق الأرقام

```python
df.to_excel('formatted.xlsx', float_format='%.1f', index=False)
```

> ✅ سيُعرض السعر 3.500 كـ 3.5

---

## 🔹 **3. حفظ إلى JSON: `to_json()`**

مفيد للبيانات التي ستُستخدم في تطبيقات ويب أو APIs.

```python
df.to_json('data.json', force_ascii=False, orient='records', indent=4)
```

- `force_ascii=False`: لدعم العربية
- `orient='records'`: كل صف ككائن
- `indent=4`: تنسيق جميل للقراءة

---

## 🔹 **4. الأخطاء الشائعة (تحليل معمق)**

| الخطأ | السبب | الحل |
|------|------|------|
| `FileNotFoundError` | المجلد غير موجود | تأكد من المسار أو أنشئ المجلد |
| `PermissionError` | الملف مفتوح في إكسل | أغلق الملف أولًا |
| النصوص العربية تظهر مشوّشة | ترميز خاطئ | استخدم `utf-8-sig` |
| الفهرس يُحفظ كعمود | لأن `index=True` (الافتراضي) | استخدم `index=False` |
| `ModuleNotFoundError: No module named 'openpyxl'` | لم يتم تثبيت المكتبة | `pip install openpyxl` |

---

## 🔹 **تمارين تطبيقية**

### ✅ التمرين 1: حفظ تقرير مبيعات
حوّل جدول مبيعاتك إلى ملف CSV بدون فهرس وبترميز عربي.

### ✅ التمرين 2: إضافة بيانات
أنشئ ملفًا جديدًا، ثم أضف إليه بيانات شهر جديد.

### ✅ التمرين 3: تقرير إكسل متعدد الأوراق
احفظ 3 جداول (يناير، فبراير، مارس) في ملف إكسل واحد بأوراق منفصلة.

### ✅ التمرين 4: تصدير لـ JSON
حوّل جدول العملاء إلى ملف JSON لاستخدامه في تطبيق ويب.

---

## 🔹 **الربط بالواقع: تصدير تقرير شهري**

### 🎯 الهدف: إرسال التقرير للإدارة

```python
# افترض أن لديك تقرير أداء
report = pd.DataFrame({
    'الموظف': ['أحمد', 'سارة'],
    'المبيعات': [15000, 22000],
    'الأداء': ['جيد', 'ممتاز']
})

# 1. حفظ كـ CSV للتحليل الآلي
report.to_csv('monthly_report.csv', index=False, encoding='utf-8-sig')

# 2. حفظ كـ إكسل لتوزيعه على الإدارة
with pd.ExcelWriter('monthly_report_manager.xlsx') as writer:
    report.to_excel(writer, sheet_name='التقرير', index=False)

print("✅ التقرير تم تصديره بنجاح إلى CSV وإكسل.")
```

> ✅ هذا هو الشكل النهائي لأي مشروع تحليل بيانات.

---

## 🔹 **نصائح احترافية**

1. ✅ استخدم دائمًا `index=False` ما لم تكن بحاجة للفهرس.
2. ✅ استخدم `utf-8-sig` لضمان ظهور العربية بشكل صحيح.
3. ✅ تجنب حفظ الملفات في مجلدات النظام (مثل C:\Windows).
4. ✅ وثّق مسار الحفظ في تعليق: `# تم الحفظ في ./output/`
5. ✅ استخدم `os.path` أو `pathlib` لإنشاء مسارات ديناميكية.

---

## 🔹 **أسئلة مراجعة**

1. لماذا نستخدم `index=False` عند الحفظ؟
2. ما الفرق بين `to_csv` و `to_excel`؟
3. كيف تُرجع ملف إكسل به عدة أوراق؟
4. ما معنى `utf-8-sig`؟
5. كيف تُضيف بيانات إلى ملف CSV موجود؟

---

## 🔹 **مراجعة سريعة (ملخص الدرس)**

| الدالة | الاستخدام |
|-------|----------|
| `to_csv()` | حفظ كملف نصي منفصل بفواصل |
| `to_excel()` | حفظ في ملف إكسل (يحتاج `openpyxl`) |
| `to_json()` | حفظ للواجهات البرمجية |
| `index=False` | عدم حفظ الفهرس |
| `encoding='utf-8-sig'` | دعم اللغة العربية |
| `mode='a'` | إضافة إلى الملف |

# 📘 **جدول مرجعي سريع: أهم دوال Pandas مع وصف بسيط**

| الدالة | الوصف البسيط | الاستخدام النموذجي |
|--------|--------------|---------------------|
| `pd.DataFrame(data)` | ينشئ جدول بيانات (DataFrame) من قاموس، قائمة، أو مصفوفة | `df = pd.DataFrame({'A': [1,2], 'B': [3,4]})` |
| `pd.read_csv('file.csv')` | يقرأ ملف CSV ويحوله إلى DataFrame | `df = pd.read_csv('data.csv')` |
| `pd.read_excel('file.xlsx')` | يقرأ ملف إكسل (ورقة واحدة أو أكثر) | `df = pd.read_excel('data.xlsx', sheet_name='Sheet1')` |
| `pd.read_json('file.json')` | يقرأ ملف JSON ويحوله إلى DataFrame | `df = pd.read_json('data.json')` |
| `df.info()` | يعرض معلومات عامة عن الجدول: الأعمدة، الأنواع، القيم المفقودة | `df.info()` |
| `df.dtypes` | يعرض نوع البيانات لكل عمود | `print(df.dtypes)` |
| `df.shape` | يُرجع عدد الصفوف والأعمدة (مثل: (100, 5)) | `rows, cols = df.shape` |
| `df.describe()` | يعرض إحصائيات رقمية: المتوسط، الانحراف، القيم القصوى | `df.describe()` |
| `df.head(n)` | يعرض أول `n` صفوف (الافتراضي: 5) | `df.head(3)` |
| `df.tail(n)` | يعرض آخر `n` صفوف | `df.tail(2)` |
| `df.isnull()` | يُرجع `True` في الخلايا التي تحتوي على قيم مفقودة | `df.isnull()` |
| `df.isnull().sum()` | يحسب عدد القيم المفقودة في كل عمود | `df.isnull().sum()` |
| `df.dropna()` | يحذف الصفوف (أو الأعمدة) التي تحتوي على قيم مفقودة | `df.dropna()` |
| `df.fillna(value)` | يملأ القيم المفقودة بقيمة معينة | `df.fillna(0)` أو `df.fillna(df.mean())` |
| `df['column']` | يُرجع عمودًا كـ `Series` | `df['الاسم']` |
| `df[['col1', 'col2']]` | يُرجع أعمدة محددة كـ `DataFrame` | `df[['الاسم', 'العمر']]` |
| `df.loc[row, col]` | يُرجع بيانات بالاسم (العلامة)، مثل: الصف "0"، العمود "الاسم" | `df.loc[0, 'الاسم']` |
| `df.iloc[row, col]` | يُرجع بيانات بالرقم (الفهرس العددي) | `df.iloc[0, 1]` |
| `df[df['العمر'] > 25]` | يُرجع الصفوف التي تحقق الشرط (الفلترة) | `df[df['السعر'] > 100]` |
| `(df['A'] > 5) & (df['B'] < 3)` | شرط منطقي باستخدام AND | استخدم دائمًا `()` مع `&` و `|` |
| `(df['A'] == 1) \| (df['B'] == 2)` | شرط منطقي باستخدام OR | استخدم `\|` بدل `or` |
| `df['المنتج'].isin(['تفاح', 'موز'])` | يتحقق مما إذا كانت القيمة في قائمة معينة | `df[df['المنتج'].isin(['A','B'])]` |
| `df['السعر'].between(10, 100)` | يتحقق مما إذا كانت القيمة ضمن نطاق معين | `df[df['السعر'].between(10, 100)]` |
| `df['جديد'] = df['A'] * df['B']` | ينشئ عمودًا جديدًا | `df['الإجمالي'] = df['السعر'] * df['الكمية']` |
| `df.rename(columns={'قديم': 'جديد'})` | يغير اسم عمود | `df.rename(columns={'الإسم': 'الاسم'})` |
| `df.drop(columns=['A', 'B'])` | يحذف أعمدة محددة | `df.drop(columns=['الوقت'], inplace=True)` |
| `df.drop(index=[0, 1])` | يحذف صفوفًا محددة | `df.drop(index=0)` |
| `df.groupby('الفئة').sum()` | يجمع البيانات حسب عمود معين | `df.groupby('المدينة')['الراتب'].mean()` |
| `df.sort_values('السعر', ascending=False)` | يرتب البيانات تصاعديًا أو تنازليًا | `df.sort_values('العمر')` |
| `df.sort_index()` | يرتب الجدول حسب الفهرس (index) | بعد `reset_index()` |
| `pd.concat([df1, df2])` | يدمج جدولين رأسيًا (إضافة صفوف) | `pd.concat([jan, feb], ignore_index=True)` |
| `pd.merge(df1, df2, on='ID')` | يربط جدولين بعمود مشترك (مثل JOIN في SQL) | `pd.merge(orders, customers, on='ID')` |
| `pd.to_datetime(df['التاريخ'])` | يحول عمود نصي إلى تاريخ | `df['التاريخ'] = pd.to_datetime(...)` |
| `df['التاريخ'].dt.month` | يستخرج الشهر من تاريخ | `.dt.year`, `.dt.day`, `.dt.day_name()` |
| `df.to_csv('file.csv', index=False)` | يحفظ الجدول كملف CSV | استخدم `encoding='utf-8-sig'` للعربية |
| `df.to_excel('file.xlsx', index=False)` | يحفظ الجدول كملف إكسل | يحتاج `openpyxl` |
| `df.to_json('file.json', force_ascii=False)` | يحفظ الجدول كملف JSON | مفيد للتطبيقات والـ APIs |
| `df.reset_index(drop=True)` | يعيد ترقيم الفهارس من 0 | بعد الفلترة أو الحذف |
| `df.copy()` | ينشئ نسخة من الجدول (يتجنب التحذيرات) | `new_df = df[df['A']>5].copy()` |
| `df.astype(int)` | يغير نوع البيانات لعمود | `df['العمر'] = df['العمر'].astype(int)` |





# 📘 **الدليل المتقدم لمكتبة Pandas: من المتوسط إلى الاحتراف** (from_good_to_greet)

> ✅ **عدد الكلمات المستهدف: ~12,000 كلمة**  
> ✅ **الجمهور: من أتقن الأساسيات ويريد الانتقال للتحليل العميق والتحضير للذكاء الاصطناعي**  
> ✅ **الهيكل: 8 دروس متقدمة، كل درس موسع كما طلبت**

---

## 📚 **الخطة التعليمية (الفهرس المبدئي)**

1. 🌀 **معالجة متعددة المستويات**: `MultiIndex`, `stack`, `unstack`, `swaplevel`  
2. 🧮 **العمليات الإحصائية المتقدمة**: `rolling`, `expanding`, `ewm`, `cov`, `corr`, `rank`, `nlargest`, `nsmallest`  
3. 📊 **Pivot والتحليل العميق**: `pivot`, `pivot_table`, `crosstab`  
4. 🧠 **التجهيز للذكاء الاصطناعي (ML)**: `get_dummies`, `cut`, `qcut`, `map`, `replace`, `astype`, `query`, `eval`  
5. ⏱️ **البيانات الزمنية المتقدمة**: `resample('1D')`, `asfreq`, `shift`, `diff`, `lag`  
6. 🔧 **التعامل مع الأخطاء والنسخ الآمن**: `copy(deep=True)`, `SettingWithCopyWarning`, `errors='ignore'`  
7. 💡 **الوظائف المتقدمة**: `apply`, `applymap`, `pipe`, `transform`, `filter`  
8. 📎 **الملحقات**: مشروع تطبيقي (تحليل أسهم)، جدول دوال متقدم، فهرس كامل

---

## 📘 **الدرس 1  : 🌀 معالجة متعددة المستويات: `MultiIndex`, `stack`, `unstack`, `swaplevel`**

### 🔹 **مقدمة: لماذا نحتاج إلى بيانات متعددة المستويات؟**

تخيل أنك محلل في شركة متعددة الفروع، ولديك بيانات مبيعات:
- حسب **السنة**
- ثم حسب **الشهر**
- ثم حسب **المدينة**
- ثم حسب **الفئة**

إذا استخدمت عمودًا واحدًا لكل مستوى، سيكون التحليل فوضويًا.

هنا تأتي أهمية **البنية الهرمية (MultiIndex)** — وهي طريقة لتمثيل بيانات ذات أبعاد متعددة في جدول ثنائي الأبعاد.

---

### 🔹 **1. إنشاء `MultiIndex`**

#### ✅ الطريقة 1: من قائمة من الأزواج

```python
import pandas as pd
import numpy as np

# بيانات: (السنة، المدينة)
index = pd.MultiIndex.from_tuples([
    ('2023', 'الرياض'),
    ('2023', 'جدة'),
    ('2024', 'الرياض'),
    ('2024', 'جدة')
], names=['السنة', 'المدينة'])

data = [100, 150, 120, 180]
df = pd.DataFrame({'المبيعات': data}, index=index)
print(df)
```

#### 🔍 الناتج:
```
              المبيعات
السنة  المدينة         
2023  الرياض       100
      جدة         150
2024  الرياض       120
      جدة         180
```

> ✅ تم تمثيل بُعدين (السنة والمدينة) كفهرس هرمي.

---

#### ✅ الطريقة 2: من قوائم باستخدام `from_product`

مفيد لتوليد كل التوافقات.

```python
years = ['2023', '2024']
cities = ['الرياض', 'جدة', 'الدمام']

index = pd.MultiIndex.from_product([years, cities], names=['السنة', 'المدينة'])
df = pd.DataFrame({'المبيعات': np.random.randint(100, 200, 6)}, index=index)
print(df)
```

---

### 🔹 **2. الوصول إلى البيانات في `MultiIndex`**

#### ✅ باستخدام `loc` مع الأسماء

```python
# مبيعات 2023 فقط
print(df.loc['2023'])

# مبيعات الرياض فقط (جميع السنوات)
print(df.xs('الرياض', level='المدينة'))

# مبيعات 2024 في الدمام
print(df.loc[('2024', 'الدمام'), 'المبيعات'])
```

---

### 🔹 **3. `stack()` و `unstack()` — تحويل بين الطول والعرض**

#### ✅ `unstack()` — رفع مستوى من الفهرس إلى أعمدة

```python
# تحويل المدينة إلى أعمدة
unstacked = df.unstack(level='المدينة')
print(unstacked)
```

#### 🔍 الناتج:
```
المدينة       الرياض  جدة  الدمام
السنة                         
2023          150  130    170
2024          160  140    180
```

> ✅ يشبه Pivot Table.

---

#### ✅ `stack()` — عكس العملية

```python
restacked = unstacked.stack()
print(restacked)
```

> ✅ يعيد البيانات إلى الشكل الهرمي.

---

### 🔹 **4. `swaplevel()` — تبديل مستويات الفهرس**

```python
# تبديل الترتيب: المدينة أولًا، ثم السنة
df_swapped = df.swaplevel().sort_index()
print(df_swapped)
```

---

### 🔹 **5. الأخطاء الشائعة**

| الخطأ | السبب | الحل |
|------|------|------|
| `KeyError` عند `loc` | لم تستخدم قوسًا مزدوجًا | `df.loc[('2023','الرياض')]` |
| `unstack()` يُنتج `NaN` | وجود تكرارات أو بيانات ناقصة | استخدم `fillna()` أولًا |
| الفهرس غير مرتب | يؤدي إلى أداء بطيء | استخدم `sort_index()` |

---

### 🔹 **تمارين**

1. أنشئ `MultiIndex` يمثل (المنتج، الفئة).
2. كيف تُرجع جميع بيانات "الإلكترونيات"؟
3. حول الجدول إلى شكل "عرضي" باستخدام `unstack`.

---

### 🔹 **الربط بالواقع: تحليل مبيعات متعددة الأبعاد**

```python
# تحليل أداء الفروع حسب السنة والشهر
monthly_sales = df.groupby(['السنة', 'المدينة']).sum()
pivot_view = monthly_sales.unstack('المدينة')
print(pivot_view)
```

> ✅ هذا الشكل يُستخدم في لوحات التحكم (Dashboards).

---

### 🔹 **نصائح احترافية**

- استخدم `MultiIndex` عندما تكون لديك بيانات هرمية.
- استخدم `xs()` للوصول إلى مستوى معين.
- استخدم `sort_index()` بعد أي تعديل.
- لا تُفرط في التعقيد — أحيانًا `pivot_table` أسهل.


# 📘 **الدرس 2  : 🧮 العمليات الإحصائية المتقدمة: `rolling`, `expanding`, `ewm`, `cov`, `corr`, `rank`, `nlargest`, `nsmallest`**

## 🔹 **مقدمة: لماذا نحتاج إلى إحصاءات متقدمة؟**

بعد تعلُّم المتوسطات والمجموعات الأساسية، تأتي مرحلة **التحليل العميق**.

في عالم التداول، التمويل، أو مراقبة الأداء، لا نكتفي بـ "متوسط المبيعات"، بل نسأل:
- ما هو **متوسط المبيعات خلال آخر 7 أيام**؟
- كيف يتغير السعر **بمرور الوقت**؟
- هل هناك **علاقة بين السعر وحجم التداول**؟
- ما هي **أفضل 3 منتجات** من حيث الأداء؟

هنا تأتي أهمية الأدوات الإحصائية المتقدمة في Pandas.

---

## 🔹 **1. `rolling()` — النافذة المتحركة (Rolling Window)**

تُستخدم لحساب إحصاءات على **نافذة زمنية متحركة** (مثلاً: آخر 5 أيام).

### 📌 المثال 1: متوسط متحرك للأسعار

```python
import pandas as pd
import numpy as np

# بيانات يومية لسعر سهم
dates = pd.date_range('2023-01-01', periods=10)
prices = [100, 102, 101, 105, 107, 106, 108, 110, 109, 112]
df = pd.DataFrame({'السعر': prices}, index=dates)

# متوسط متحرك على آخر 3 أيام
df['المتوسط_المتحرك'] = df['السعر'].rolling(window=3).mean()
print(df)
```

#### 🔍 الناتج:
```
            السعر  المتوسط_المتحرك
2023-01-01  100             NaN
2023-01-02  102             NaN
2023-01-03  101       101.000000
2023-01-04  105       102.666667
2023-01-05  107       104.333333
...
```

> ✅ أول ناتجين `NaN` لأن النافذة تحتاج 3 قيم.

---

### ✅ دوال متاحة مع `rolling`
- `.mean()` — المتوسط المتحرك
- `.std()` — الانحراف المعياري المتحرك
- `.sum()` — المجموع المتحرك
- `.min()`, `.max()` — الحد الأدنى/الأقصى

---

## 🔹 **2. `expanding()` — التوسع التراكمي**

يحسب الإحصاء من البداية حتى النقطة الحالية.

### 📌 المثال 2: المتوسط التراكمي

```python
df['المتوسط_التراكمي'] = df['السعر'].expanding().mean()
print(df)
```

#### 🔍 الناتج:
```
            السعر  المتوسط_التراكمي
2023-01-01  100          100.000000
2023-01-02  102          101.000000
2023-01-03  101          101.000000
2023-01-04  105          102.000000
```

> ✅ يُستخدم في تتبع الأداء التراكمي.

---

## 🔹 **3. `ewm()` — المتوسط المتحرك المرجح أسيًا (Exponentially Weighted)**

يعطي وزنًا أكبر للقيم الحديثة.

### 📌 المثال 3: EWMA للسعر

```python
df['ewm'] = df['السعر'].ewm(alpha=0.3).mean()
```

> ✅ `alpha` (0 < α ≤ 1): كلما زاد، زاد تركيزك على القيم الحديثة.

---

## 🔹 **4. `cov()` و `corr()` — التباين وارتباط بيرسون**

### 📌 المثال 4: ارتباط السعر مع الحجم

```python
df['الحجم'] = [1000, 1200, 900, 1300, 1100, 1400, 1050, 1600, 1350, 1700]

# معامل الارتباط
correlation = df['السعر'].corr(df['الحجم'])
print(f"معامل الارتباط: {correlation:.2f}")

# التباين
covariance = df['السعر'].cov(df['الحجم'])
print(f"التباين: {covariance:.2f}")
```

> ✅ إذا كان `corr > 0.7`، فهناك علاقة قوية.

---

## 🔹 **5. `rank()` — ترتيب القيم**

يُعطي لكل قيمة "مركزها" بين القيم الأخرى.

### 📌 المثال 5: ترتيب المبيعات

```python
df['الرتبة'] = df['السعر'].rank(ascending=False)
```

> ✅ القيمة الأعلى = الرتبة 1.

---

## 🔹 **6. `nlargest()` و `nsmallest()`**

### 📌 المثال 6: أفضل 3 أسعار

```python
top_3 = df['السعر'].nlargest(3)
bottom_2 = df['الحجم'].nsmallest(2)
```

> ✅ بديل أسرع من `sort_values().head(n)`.

---

## 🔹 **الأخطاء الشائعة**

| الخطأ | السبب | الحل |
|------|------|------|
| `NaN` في `rolling` | النافذة غير مكتملة | تجاهل أول `n-1` صفوف |
| `corr()` يُرجع `NaN` | عمود به قيم مفقودة | استخدم `dropna()` أولًا |
| `ewm` لا يستجيب بسرعة | `alpha` صغير جدًا | جرب `alpha=0.5` |

---

## 🔹 **تمارين**

1. احسب المتوسط المتحرك لآخر 5 أيام.
2. ما معامل الارتباط بين السعر والحجم؟
3. أظهر أفضل 2 يوم من حيث السعر.

---

## 🔹 **الربط بالواقع: تحليل تداول الأسهم**

```python
# 1. المتوسط المتحرك (مؤشر شائع في التداول)
df['MA_7'] = df['السعر'].rolling(7).mean()

# 2. الارتباط بين السعر والحجم
corr = df['السعر'].corr(df['الحجم'])

# 3. أفضل 5 أيام من حيث الأداء
top_days = df['السعر'].nlargest(5)

print("📊 تقرير التداول:")
print(f"المتوسط المتحرك 7 أيام: {df['MA_7'].iloc[-1]:.2f}")
print(f"الارتباط السعر-الحجم: {corr:.2f}")
print("أفضل 5 أيام:", top_days.index.strftime('%Y-%m-%d').tolist())
```

> ✅ هذا التحليل يُستخدم في استراتيجيات التداول الآلي.

---

## 🔹 **نصائح احترافية**

- استخدم `rolling` في البيانات الزمنية.
- استخدم `ewm` عندما تكون القيم الحديثة أكثر أهمية.
- تحقق من `corr()` قبل بناء نموذج تنبؤ.
- استخدم `nlargest` بدل `sort_values().head()` للأداء.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `rolling` و `expanding`؟
2. ما معنى `alpha` في `ewm`؟
3. كيف تحسب معامل الارتباط بين عمودين؟
4. ما الفرق بين `rank` و `sort_values`؟
5. متى نستخدم `nsmallest`؟

# 📘 **الدرس 3  : 📊 Pivot والتحليل العميق: `pivot`, `pivot_table`, `crosstab`**

## 🔹 **مقدمة: لماذا نحتاج إلى Pivot؟**

تخيل أن لديك جدول مبيعات به أعمدة:
- التاريخ
- المدينة
- الفئة
- المبيعات

وتريد الإجابة على سؤال بسيط:
> "ما إجمالي المبيعات لكل مدينة حسب الفئة؟"

إذا استخدمت `groupby`، تحصل على جدول طولي.  
لكن إذا أردت جدولًا **عرضيًا** (مثل إكسل Pivot)، فتحتاج إلى:
> ✅ `pivot` أو `pivot_table`

هذه الأدوات تحوّل البيانات من شكل "قائمي" إلى شكل "مصفوفي"، وهو مثالي للتقارير واللوحات التفاعلية.

---

## 🔹 **1. `pivot()` — إعادة تشكيل البيانات (لقيم فريدة فقط)**

يُستخدم عندما **لا توجد تكرارات** في التوليفة (index, columns).

### 📌 المثال 1: تحويل الفئات إلى أعمدة

```python
import pandas as pd

data = {
    'المدينة': ['الرياض', 'الرياض', 'جدة', 'جدة'],
    'الفئة': ['فواكه', 'إلكترونيات', 'فواكه', 'إلكترونيات'],
    'المبيعات': [100, 200, 150, 180]
}
df = pd.DataFrame(data)

# تحويل الفئة إلى أعمدة
pivoted = df.pivot(index='المدينة', columns='الفئة', values='المبيعات')
print(pivoted)
```

#### 🔍 الناتج:
```
الفئة     إلكترونيات  فواكه
المدينة                
الرياض          200    100
جدة             180    150
```

> ✅ جدول نظيف يُسهل المقارنة.

---

### ⚠️ ماذا يحدث إذا كانت هناك تكرارات؟

```python
# أضف صفًا مكررًا
df_duplicate = df.append({'المدينة': 'الرياض', 'الفئة': 'فواكه', 'المبيعات': 120}, ignore_index=True)

# هذا سيعطي خطأ:
# df_duplicate.pivot(...) → ValueError
```

> ✅ الحل: استخدم `pivot_table` بدل `pivot`.

---

## 🔹 **2. `pivot_table()` — Pivot آمن مع التكرارات**

يسمح بالتكرارات ويُطبّق دالة تجميع (مثل `sum`, `mean`).

### 📌 المثال 2: مع التكرارات

```python
# استخدام pivot_table مع مجموع
pivoted_table = df_duplicate.pivot_table(
    index='المدينة',
    columns='الفئة',
    values='المبيعات',
    aggfunc='sum'  # أو 'mean', 'count'
)
print(pivoted_table)
```

#### 🔍 الناتج:
```
الفئة     إلكترونيات  فواكه
المدينة                
الرياض          200    220  ← 100 + 120
جدة             180    150
```

> ✅ تم تجميع القيم تلقائيًا.

---

### ✅ خيارات مهمة في `pivot_table`

| الخيار | الوظيفة |
|--------|--------|
| `aggfunc='sum'` | الدالة المُطبقة (sum, mean, count, ...) |
| `fill_value=0` | استبدال `NaN` بقيمة (مثلاً 0) |
| `margins=True` | إضافة صف/عمود "الإجمالي" |
| `columns` متعدد | `columns=['A', 'B']` |

---

### 📌 المثال 3: تقرير شامل مع إجماليات

```python
report = df_duplicate.pivot_table(
    index='المدينة',
    columns='الفئة',
    values='المبيعات',
    aggfunc='sum',
    fill_value=0,
    margins=True,
    margins_name='الإجمالي العام'
)
print(report)
```

#### 🔍 الناتج:
```
الفئة       إلكترونيات  فواكه  الإجمالي العام
المدينة                                  
الرياض             200    220           420
جدة                180    150           330
الإجمالي العام        380    370           750
```

> ✅ تقرير جاهز للعرض الإداري.

---

## 🔹 **3. `crosstab()` — جدول التقابل (Contingency Table)**

يُستخدم لحساب **التكرارات** بين عمودين (مثل: كم عدد العملاء الذكور في كل فئة؟).

### 📌 المثال 4: توزيع العملاء حسب الجنس والفئة

```python
data_customers = {
    'الجنس': ['ذكر', 'أنثى', 'ذكر', 'أنثى', 'ذكر'],
    'الفئة': ['مبيعات', 'تسويق', 'مبيعات', 'مبيعات', 'تسويق']
}
df_cust = pd.DataFrame(data_customers)

cross = pd.crosstab(df_cust['الجنس'], df_cust['الفئة'])
print(cross)
```

#### 🔍 الناتج:
```
الفئة    تسويق  مبيعات
الجنس              
أنثى        1      1
ذكر         1      2
```

> ✅ مثالي للتحليل الديموغرافي.

---

### ✅ إضافات في `crosstab`

```python
pd.crosstab(
    df_cust['الجنس'],
    df_cust['الفئة'],
    normalize='index'  # النسبة المئوية لكل صف
)
```

> ✅ يُظهر أن 50% من الذكور في "مبيعات".

---

## 🔹 **الأخطاء الشائعة**

| الخطأ | السبب | الحل |
|------|------|------|
| `ValueError` في `pivot` | تكرار في (index, columns) | استخدم `pivot_table` |
| `pivot_table` يُنتج `NaN` | بيانات ناقصة | استخدم `fill_value=0` |
| `crosstab` لا يُظهر النسب | لم تستخدم `normalize` | أضف `normalize='all'` أو `'index'` |

---

## 🔹 **تمارين**

1. حول جدول مبيعاتك إلى Pivot حسب المدينة والشهر.
2. أنشئ `crosstab` يُظهر توزيع المنتجات حسب الفئة والمدينة.
3. أضف إجماليات إلى `pivot_table`.

---

## 🔹 **الربط بالواقع: تقرير أداء الفروع**

```python
# افترض أن لديك بيانات شهرية
monthly_pivot = df.pivot_table(
    index='المدينة',
    columns='الفئة',
    values='المبيعات',
    aggfunc='sum',
    fill_value=0
)

print("📊 أداء الفروع حسب الفئة:")
print(monthly_pivot)
```

> ✅ هذا التقرير يُستخدم في اتخاذ قرارات التسويق.

---

## 🔹 **نصائح احترافية**

- استخدم `pivot` فقط عندما تكون البيانات فريدة.
- استخدم `pivot_table` في 90% من الحالات.
- استخدم `crosstab` للتحليلات الديموغرافية والإحصائية.
- وثّق `aggfunc` المستخدم في التقرير.
- استخدم `margins=True` لعرض الإجماليات.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `pivot` و `pivot_table`؟
2. ما معنى `aggfunc`؟
3. كيف تُظهر النسب المئوية في `crosstab`؟
4. ما وظيفة `fill_value`؟
5. متى نستخدم `margins=True`؟

# 📘 **الدرس 4  : 🧠 التجهيز للذكاء الاصطناعي (ML): `get_dummies`, `cut`, `qcut`, `map`, `replace`, `astype`, `query`, `eval`**


## 🔹 **مقدمة: لماذا نحتاج إلى تجهيز البيانات للذكاء الاصطناعي؟**

قبل أن تُدخل البيانات إلى نموذج تعلُّم آلي (مثل الانحدار أو التصنيف)، يجب أن تكون:
- **رقمية** (النماذج لا تفهم النصوص)
- **منضبطة** (بدون قيم شاذة)
- **مصنفة** (إذا كانت هناك فئات)
- **نظيفة** (بدون أخطاء أو تنسيق خاطئ)

هذا الدرس يُعلّمك **أدوات التحويل والتجهيز** التي تُستخدم في كل مشروع ML.

---

## 🔹 **1. `pd.get_dummies()` — تحويل النصوص إلى أرقام (One-Hot Encoding)**

النماذج لا تفهم "مبيعات"، "تسويق"، بل تحتاج أرقامًا.

### 📌 المثال 1: تحويل الفئات إلى أعمدة رقمية

```python
import pandas as pd

data = {
    'الاسم': ['أحمد', 'سارة', 'علي'],
    'القسم': ['مبيعات', 'تسويق', 'مبيعات'],
    'الراتب': [5000, 7000, 6000]
}
df = pd.DataFrame(data)

# تحويل القسم إلى أعمدة رقمية
df_encoded = pd.get_dummies(df, columns=['القسم'])
print(df_encoded)
```

#### 🔍 الناتج:
```
   الاسم  الراتب  القسم_مبيعات  القسم_تسويق
0   أحمد  5000            1            0
1   سارة  7000            0            1
2   علي   6000            1            0
```

> ✅ الآن يمكن إدخال البيانات إلى نموذج ML.

---

### ✅ خيارات مهمة
- `drop_first=True`: لتجنب "الخداع المتعدد" (Multicollinearity)
- `prefix='Dept'`: لتغيير اسم العمود

```python
pd.get_dummies(df, columns=['القسم'], drop_first=True)
```

---

## 🔹 **2. `pd.cut()` — تقسيم الأرقام إلى فئات متساوية (Binning)**

مثلاً: تحويل "العمر" إلى "شباب، بالغ، كبير".

### 📌 المثال 2: تقسيم العمر

```python
ages = [20, 25, 35, 45, 55, 65]
df_ages = pd.DataFrame({'العمر': ages})

# تقسيم إلى 3 فئات: 20-40، 40-60، 60-80
df_ages['الفئة'] = pd.cut(df_ages['العمر'], bins=[20, 40, 60, 80], labels=['شباب', 'بالغ', 'كبير'])
print(df_ages)
```

#### 🔍 الناتج:
```
   العمر  الفئة
0     20   شباب
1     25   شباب
2     35   شباب
3     45   بالغ
4     55   بالغ
5     65   كبير
```

> ✅ مفيد للتصنيف.

---

## 🔹 **3. `pd.qcut()` — التقسيم حسب النسب المئوية (Quantile Binning)**

يُقسّم البيانات إلى فئات ذات عدد متساوٍ من العناصر.

### 📌 المثال 3: تقسيم الرواتب إلى "منخفض، متوسط، عالي"

```python
salaries = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]
df_sal = pd.DataFrame({'الراتب': salaries})

# 3 فئات: 33% منخفض، 33% متوسط، 33% عالي
df_sal['الفئة'] = pd.qcut(df_sal['الراتب'], q=3, labels=['منخفض', 'متوسط', 'عالي'])
print(df_sal)
```

#### 🔍 الناتج:
```
   الراتب    الفئة
0   3000   منخفض
1   4000   منخفض
2   5000   متوسط
3   6000   متوسط
4   7000   عالي
5   8000   عالي
6   9000   عالي
7  10000   عالي
```

> ✅ مثالي للتصنيف العادل.

---

## 🔹 **4. `map()` — استبدال قيم بناءً على خريطة**

### 📌 المثال 4: تحويل الأرقام إلى نصوص

```python
df['التقييم'] = [1, 2, 3]
rating_map = {1: 'ضعيف', 2: 'متوسط', 3: 'ممتاز'}
df['التقييم_النصي'] = df['التقييم'].map(rating_map)
```

---

## 🔹 **5. `replace()` — استبدال قيم معينة**

### 📌 المثال 5: تصحيح أخطاء إدخال

```python
df['المدينة'] = df['المدينة'].replace('الرياص', 'الرياض')
df['الراتب'] = df['الراتب'].replace(0, np.nan)  # استبدال 0 بـ NaN
```

---

## 🔹 **6. `astype()` — تغيير نوع البيانات**

ضروري قبل التحليل.

```python
df['العمر'] = df['العمر'].astype(int)
df['المنتج'] = df['المنتج'].astype('category')  # لتوفير الذاكرة
```

---

## 🔹 **7. `query()` — تصفية البيانات بجملة نصية**

بديل أنيق للشروط المعقدة.

```python
# بدل:
# df[(df['العمر'] > 25) & (df['الراتب'] < 7000)]

# استخدم:
filtered = df.query('العمر > 25 and الراتب < 7000')
```

> ✅ أكثر قراءة.

---

## 🔹 **8. `eval()` — تقييم تعبير رياضي كنص**

```python
# بدل:
# df['إجمالي'] = df['السعر'] * df['الكمية']

# استخدم:
df = df.eval('الإجمالي = السعر * الكمية')
```

> ✅ مفيد في الأنابيب.

---

## 🔹 **الأخطاء الشائعة**

| الخطأ | السبب | الحل |
|------|------|------|
| `get_dummies` يُنتج كثير من الأعمدة | فئات كثيرة جدًا | استخدم `pd.cut` أولًا |
| `qcut` يُعطي خطأ | تكرار في القيم | استخدم `duplicates='drop'` |
| `map` يُنتج `NaN` | قيمة غير موجودة في الخريطة | تأكد من تطابق القيم |
| `query` لا يعمل مع أسماء تحتوي مسافات | مثل `first name` | استخدم backticks: `` `first name` `` |

---

## 🔹 **تمارين**

1. حوّل عمود "الجنس" إلى أعمدة رقمية باستخدام `get_dummies`.
2. قسّم "العمر" إلى 4 فئات باستخدام `cut`.
3. استخدم `query` لتصفية الموظفين الذين رواتبهم بين 5000 و8000.

---

## 🔹 **الربط بالواقع: إعداد بيانات لنموذج ML**

```python
# 1. استبدال النصوص
df['الجنس'] = df['الجنس'].map({'ذكر': 1, 'أنثى': 0})

# 2. تصنيف العمر
df['فئة_العمر'] = pd.cut(df['العمر'], bins=3, labels=[1,2,3])

# 3. ترميز الفئات
df = pd.get_dummies(df, columns=['القسم'], drop_first=True)

# 4. تنظيف البيانات
df['الراتب'] = df['الراتب'].replace(0, df['الراتب'].median())

# 5. التحقق من الأنواع
df = df.astype({'العمر': 'int', 'الجنس': 'int'})

print("✅ البيانات جاهزة للنموذج!")
```

> ✅ هذا هو الشكل النهائي لبيانات ML.

---

## 🔹 **نصائح احترافية**

- استخدم `get_dummies` بحذر مع الفئات الكثيرة.
- استخدم `qcut` للتقسيم العادل، و `cut` للنطاقات الثابتة.
- استخدم `query` و `eval` لتحسين قراءة الكود.
- وثّق كل خطوة تحويل.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `cut` و `qcut`؟
2. لماذا نستخدم `get_dummies` في ML؟
3. ما الفرق بين `map` و `replace`؟
4. كيف تستخدم `query` مع شرط منطقي؟
5. ما فائدة `eval`؟

# 📘 **الدرس 5  : ⏱️ البيانات الزمنية المتقدمة: `resample('1D')`, `asfreq`, `shift`, `diff`, `lag`**

## 🔹 **مقدمة: لماذا نحتاج إلى معالجة زمنية متقدمة؟**

في تحليل الأسهم، المبيعات، أو بيانات الاستشعار، لا يكفي معرفة "ما حدث"، بل يجب أن نفهم:
- كيف تتغير القيم بمرور الوقت؟
- ما الفرق بين اليوم والبارحة؟
- كيف نُعيد تردد البيانات (من دقائق إلى أيام)؟
- هل هناك اتجاه تصاعدي؟

هنا تأتي أهمية الأدوات الزمنية المتقدمة في Pandas.

---

## 🔹 **1. `resample()` — إعادة عيّنة البيانات حسب التردد**

تُستخدم لتغيير **دقة البيانات الزمنية** (مثلاً: من دقائق إلى ساعات).

### 📌 المثال 1: من بيانات يومية إلى أسبوعية

```python
import pandas as pd
import numpy as np

# بيانات يومية
dates = pd.date_range('2023-01-01', periods=30, freq='D')
sales = np.random.randint(100, 200, 30)
df = pd.DataFrame({'المبيعات': sales}, index=dates)

# تحويل إلى أسبوعية (مجموع كل أسبوع)
weekly = df.resample('W').sum()
print(weekly.head())
```

#### 🔍 الناتج:
```
            المبيعات
2023-01-01      580
2023-01-08      620
2023-01-15      590
...
```

> ✅ `W` = أسبوع، `D` = يوم، `M` = شهر، `H` = ساعة

---

### ✅ ترددات شائعة في `resample`
| التردد | المعنى |
|--------|--------|
| `'D'` | يوم |
| `'W'` | أسبوع |
| `'M'` | شهر |
| `'Q'` | ربع سنوي |
| `'Y'` | سنة |
| `'H'` | ساعة |
| `'T'` أو `'min'` | دقيقة |

---

### 📌 المثال 2: متوسط شهري

```python
monthly_avg = df.resample('M').mean()
```

> ✅ مفيد لتحليل الاتجاهات الطويلة.

---

## 🔹 **2. `asfreq()` — تغيير التردد دون تجميع**

يُستخدم عندما تريد **إعادة تحديد التردد مع ملء الفراغات**.

### 📌 المثال 3: من يومي إلى يومي (مع ملء)

```python
# افترض أن بعض الأيام مفقودة
df_sparse = df[df.index.day % 3 == 0]  # كل 3 أيام

# ملء الأيام المفقودة
df_dense = df_sparse.asfreq('D', fill_value=0)
print(df_dense.head())
```

> ✅ يُستخدم في البيانات الناقصة.

---

## 🔹 **3. `shift()` — إزاحة البيانات (Lag or Lead)**

يُستخدم لحساب:
- القيمة السابقة (lag)
- القيمة القادمة (lead)

### 📌 المثال 4: حساب السعر السابق

```python
df['السعر_البارحة'] = df['المبيعات'].shift(1)
df['التغير'] = df['المبيعات'] - df['السعر_البارحة']
```

> ✅ `shift(1)` = قيمة الأمس  
> `shift(-1)` = قيمة الغد (lead)

---

## 🔹 **4. `diff()` — الفرق بين القيم المتتالية**

مفيد لحساب **التغير اليومي**.

### 📌 المثال 5: التغير اليومي في المبيعات

```python
df['التغير_اليومي'] = df['المبيعات'].diff()
```

#### 🔍 الناتج:
```
2023-01-01     NaN
2023-01-02    10.0   ← الفرق بين 110 و100
2023-01-03   -15.0   ← الفرق بين 95 و110
```

> ✅ أول قيمة `NaN` لأن لا يوجد "أمس" لها.

---

### ✅ `diff()` مع `resample`

```python
# التغير الأسبوعي
df.resample('W').sum().diff()
```

---

## 🔹 **5. `lag` — ليس دالة مباشرة، لكنها مفهوم**

في Pandas، لا توجد دالة `lag()`، لكن:
```python
df['lag_1'] = df['المبيعات'].shift(1)  # هذا هو الـ lag
```

> ✅ يُستخدم في نماذج ARIMA، والتنبؤ.

---

## 🔹 **الأخطاء الشائعة**

| الخطأ | السبب | الحل |
|------|------|------|
| `resample` لا يعمل | الفهرس ليس من نوع `datetime` | استخدم `set_index('التاريخ')` أو `pd.to_datetime()` |
| `shift` يُنتج `NaN` | طبيعي في أول/آخر قيمة | تجاهله أو املأه بـ `fillna(0)` |
| `diff` يُعطي نتائج غريبة | لأن البيانات غير مرتبة زمنيًا | تأكد من `df.sort_index()` |
| `asfreq` يُفقد البيانات | إذا لم يكن الفهرس متسلسلًا | تأكد من التواريخ المتتالية |

---

## 🔹 **تمارين**

1. حوّل بياناتك اليومية إلى شهرية باستخدام `resample('M').sum()`.
2. أنشئ عمودًا باسم "الأمس" يحتوي على قيمة اليوم السابق.
3. احسب التغير اليومي في السعر.
4. ما هو التغير النسبي (النسبة المئوية) بين يوم وآخر؟ (تلميح: استخدم `pct_change()`)

---

## 🔹 **الربط بالواقع: تحليل سعر السهم**

```python
# افترض أن df['السعر'] يحتوي على أسعار يومية
df['السعر_الأمس'] = df['السعر'].shift(1)
df['التغير'] = df['السعر'].diff()
df['النسبة_المئوية'] = df['السعر'].pct_change() * 100
df['متوسط_7_أيام'] = df['السعر'].rolling(7).mean()

# تحويل إلى أسبوعي
weekly_price = df['السعر'].resample('W').last()

print("📈 تحليل السعر اليومي:")
print(df[['التغير', 'النسبة_المئوية']].head())
```

> ✅ هذا التحليل يُستخدم في التداول الكمي.

---

## 🔹 **نصائح احترافية**

- استخدم `resample` للتحليل متعدد الترددات.
- استخدم `shift` لحساب المؤشرات الزمنية.
- استخدم `diff` للكشف عن التغيرات المفاجئة.
- تأكد من أن الفهرس زمني ومرتب قبل أي عملية.
- استخدم `fillna()` بعد `shift` إذا لزم.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `resample` و `asfreq`؟
2. كيف تحسب السعر السابق؟
3. ما معنى `shift(-1)`؟
4. ما الفرق بين `diff` و `pct_change`؟
5. لماذا `resample` يتطلب فهرسًا زمنيًا؟

# 📘 **الدرس 6  : 🔧 التعامل مع الأخطاء والنسخ الآمن: `copy(deep=True)`, `SettingWithCopyWarning`, `errors='ignore'`**


## 🔹 **مقدمة: لماذا تظهر التحذيرات؟ وكيف نتعامل معها باحترافية؟**

حتى المبرمجين المتمرسين يواجهون تحذيرًا غامضًا من Pandas:
```
SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame
```

هذا التحذير **ليس خطأ**، لكنه **تحذير من مشكلة محتملة**:
> قد تُعدّل نسخة من البيانات، وتفقد التغييرات!

في هذا الدرس، ستفهم:
- لماذا يحدث هذا التحذير؟
- كيف تتجنبه؟
- متى تستخدم `copy()`؟
- كيف تُهمِل الأخطاء بوعي (وليس بتهور)؟

---

## 🔹 **1. ما هو `SettingWithCopyWarning`؟**

### 📌 المثال 1: الكود الذي يُسبب التحذير

```python
import pandas as pd

df = pd.DataFrame({
    'المنتج': ['تفاح', 'موز', 'لابتوب'],
    'السعر': [3.5, 2.0, 2500],
    'الفئة': ['فواكه', 'فواكه', 'إلكترونيات']
})

# ❌ هذا الكود يُسبب التحذير
(filtered_df)['السعر'] = filtered_df['السعر'] * 1.1
```

#### 🔍 السبب:
- `df[df['الفئة'] == 'فواكه']` يُنتج **نسخة مؤقتة**
- ثم تحاول تعديلها: `['السعر'] = ...`
- Pandas لا يعرف إن كنت تقصد التعديل على الأصل أم النسخة

> ⚠️ النتيجة: التغيير قد لا يُحفظ!

---

## 🔹 **2. الحل الصحيح: استخدام `.copy()`**

### ✅ الطريقة 1: إنشاء نسخة صريحة

```python
filtered_df = df[df['الفئة'] == 'فواكه'].copy()
filtered_df['السعر'] = filtered_df['السعر'] * 1.1
```

> ✅ الآن Pandas يعرف أنك تعمل على نسخة، ولا يُصدر تحذيرًا.

---

### ✅ الطريقة 2: التعديل على الأصل باستخدام `.loc`

```python
# ✅ التعديل على الجدول الأصلي مباشرة
df.loc[df['الفئة'] == 'فواكه', 'السعر'] = df.loc[df['الفئة'] == 'فواكه', 'السعر'] * 1.1
```

> ✅ لا تحذير، لأنك تستخدم `.loc` على الجدول الأصلي.

---

## 🔹 **3. `copy(deep=True)` vs `copy(deep=False)`**

عند نسخ DataFrame، يمكنك التحكم في عمق النسخ.

### ✅ `deep=True` (الافتراضي)
- يُنشئ نسخة مستقلة تمامًا
- التغييرات على النسخة لا تؤثر على الأصل
- يستهلك ذاكرة أكثر

```python
df_copy = df.copy(deep=True)
```

### ✅ `deep=False`
- يُنشئ نسخة سطحية (تحتفظ بالإشارات إلى نفس البيانات)
- التغييرات على البيانات قد تؤثر على الأصل
- نادرًا ما يُستخدم

> ✅ استخدم دائمًا `deep=True` ما لم تكن لديك أسباب تقنية.

---

## 🔹 **4. استخدام `errors='ignore'` في العمليات**

بعض الدوال تُصدر أخطاء إذا فشلت (مثل `drop` على عمود غير موجود).

### 📌 المثال 2: تجنب خطأ عند حذف عمود قد لا يوجد

```python
# ❌ قد يُعطي KeyError
df = df.drop(columns=['عمود_مؤقت'])

# ✅ الحل الآمن
df = df.drop(columns=['عمود_مؤقت'], errors='ignore')
```

> ✅ مفيد في الأنابيب التلقائية.

---

### 📌 أماكن شائعة لاستخدام `errors='ignore'`
- `drop(columns=..., errors='ignore')`
- `rename(columns=..., errors='ignore')` (في بعض السياقات)
- `fillna(value, errors='ignore')` — نادر

---

## 🔹 **5. الأخطاء الشائعة في النسخ**

| الخطأ | المثال | الحل |
|------|--------|------|
| التعديل على "عرض" بدون `copy()` | `df[df>0]['A'] = 1` | استخدم `.loc` أو `.copy()` |
| نسيان `copy()` بعد الفلترة | `sub = df[df['X']>5]` ثم تعديل | أضف `.copy()` |
| استخدام `copy(deep=False)` بدون فهم | قد يؤدي إلى تغييرات غير متوقعة | استخدم `deep=True` |
| كتم التحذيرات بدون فهم | `pd.options.mode.chained_assignment = None` | لا تفعل ذلك! |

---

## 🔹 **6. كيف تُطفئ التحذيرات؟ (بشكل آمن)**

> ⚠️ لا ننصح بكتم التحذيرات، لكن إذا كنت متأكدًا:

```python
import pandas as pd
import warnings

# كتم تحذيرات Pandas فقط
pd.options.mode.chained_assignment = None  # 'warn' أو None

# أو كتم جميع التحذيرات (غير موصى به)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)
```

> ✅ فقط في الإنتاج، وعندما تكون متأكدًا من سلامة الكود.

---

## 🔹 **تمارين**

1. أعد كتابة هذا الكود ليكون آمنًا:
   ```python
   temp = df[df['السعر'] > 100]
   temp['السعر'] = temp['السعر'] * 0.9
   ```
2. لماذا `df.copy()` أفضل من `df` مباشرة؟
3. في أي حالات تستخدم `errors='ignore'`؟

---

## 🔹 **الربط بالواقع: أنبوب معالجة تلقائي**

```python
def clean_data(df):
    # 1. تصفية
    filtered = df[df['الحالة'] == 'نشط'].copy()
    
    # 2. تعديل آمن
    filtered.loc[filtered['المنتج'] == 'موز', 'السعر'] += 0.5
    
    # 3. حذف عمود قد لا يوجد
    filtered = filtered.drop(columns=['temp_id'], errors='ignore')
    
    return filtered

# استخدام آمن
clean_df = clean_data(raw_df)
```

> ✅ هذا النمط يُستخدم في أنظمة ETL.

---

## 🔹 **نصائح احترافية**

- دائمًا استخدم `.copy()` بعد الفلترة إذا كنت ستعيد التعديل.
- استخدم `.loc` للتعديل على الأصل.
- لا تكتم التحذيرات — فهمّها وعالجها.
- استخدم `errors='ignore'` فقط في السيناريوهات الآمنة.
- وثّق كل استخدام لـ `copy()` أو `errors='ignore'`.

---

## 🔹 **أسئلة مراجعة**

1. ما معنى `SettingWithCopyWarning`؟
2. متى نستخدم `.copy()`؟
3. ما الفرق بين `deep=True` و `deep=False`؟
4. كيف تتجنب `KeyError` عند حذف عمود؟
5. هل من الآمن كتم التحذيرات؟


# 📘 **الدرس 7  : 💡 الوظائف المتقدمة: `apply`, `applymap`, `pipe`, `transform`, `filter`**

## 🔹 **مقدمة: لماذا نحتاج إلى وظائف متقدمة؟**

حتى الآن، استخدمت دوال Pandas الجاهزة مثل:
- `sum()`, `mean()`, `fillna()`

لكن ماذا لو أردت:
- تطبيق دالة **مخصصة** على عمود؟
- تنفيذ سلسلة من **التحولات المنطقية**؟
- إجراء **تنظيف معقد** على كل خلية؟
- تصفيّة الصفوف بمنطق غير تقليدي؟

هنا تأتي أهمية **الوظائف المتقدمة** التي تمنحك **تحكمًا كاملاً** في البيانات.

---

## 🔹 **1. `apply()` — تطبيق دالة على صفوف أو أعمدة**

تُستخدم لتطبيق دالة مخصصة على:
- **كل صف** (`axis=1`)
- **كل عمود** (`axis=0`)

### 📌 المثال 1: حساب ضريبة + رسوم شحن

```python
import pandas as pd

df = pd.DataFrame({
    'المنتج': ['تفاح', 'موز', 'لابتوب'],
    'السعر': [3.5, 2.0, 2500],
    'الوزن': [0.2, 0.1, 5.0],
    'الفئة': ['فواكه', 'فواكه', 'إلكترونيات']
})

# دالة مخصصة لحساب السعر النهائي
def calculate_final_price(row):
    tax = row['السعر'] * 0.15
    shipping = 10 if row['الوزن'] > 1 else 2
    return row['السعر'] + tax + shipping

# تطبيق الدالة على كل صف
df['السعر_النهائي'] = df.apply(calculate_final_price, axis=1)
print(df)
```

#### 🔍 الناتج:
```
   المنتج  السعر  الوزن       الفئة  السعر_النهائي
0    تفاح    3.5   0.2       فواكه          5.85
1     موز    2.0   0.1       فواكه          4.30
2   لابتوب 2500.0   5.0  إلكترونيات       2860.00
```

> ✅ `axis=1` = تطبيق على الصفوف  
> `axis=0` = تطبيق على الأعمدة

---

### ✅ استخدام `apply` مع دوال بسيطة

```python
# تحويل السعر إلى دولار (بافتراض 3.75 ريال = دولار)
df['السعر_دولار'] = df['السعر'].apply(lambda x: x / 3.75)
```

---

## 🔹 **2. `applymap()` — تطبيق دالة على كل خلية (قديم)**

> ⚠️ ملاحظة: `applymap()` **تمت إزالته في Pandas 2.1+**، واستُبدِل بـ `map()` للـ Series.

لكن للفهم:

```python
# ❌ قديم (لا يعمل في الإصدارات الحديثة)
# df.applymap(lambda x: str(x).upper())

# ✅ البديل: استخدام `map` على كل عمود نصي
for col in df.select_dtypes(include='object').columns:
    df[col] = df[col].map(str.upper)
```

---

## 🔹 **3. `pipe()` — بناء أنابيب معالجة (كـ Unix pipes)**

مثالي لكتابة كود **نظيف وسلس**، مثل:
```python
result = (df
    .clean_data()
    .add_taxes()
    .filter_active()
    .calculate_report()
)
```

### 📌 المثال 2: أنبوب تنظيف بيانات

```python
def add_tax(df, rate=0.15):
    df = df.copy()
    df['السعر_بعد_الضريبة'] = df['السعر'] * (1 + rate)
    return df

def filter_electronics(df):
    return df[df['الفئة'] == 'إلكترونيات']

def rename_columns(df):
    return df.rename(columns={'السعر': 'السعر_الأصلي'})

# سلسلة من التحويلات
result = (df
    .pipe(add_tax, rate=0.15)
    .pipe(filter_electronics)
    .pipe(rename_columns)
)

print(result)
```

#### 🔍 الناتج:
```
   المنتج  السعر_الأصلي  الوزن       الفئة  السعر_بعد_الضريبة
2  لابتوب        2500.0    5.0  إلكترونيات           2875.0
```

> ✅ الكود قابل للقراءة والصيانة.

---

## 🔹 **4. `transform()` — تطبيق دالة مع الحفاظ على الشكل**

مفيد عندما تريد:
- تطبيق دالة على مجموعة، لكن تُرجع نتائج بنفس طول الجدول.

### 📌 المثال 3: طرح المتوسط من كل قيمة (Centering)

```python
# طرح متوسط السعر من كل سعر
df['السعر_معدل'] = df['السعر'].transform(lambda x: x - x.mean())
print(df[['المنتج', 'السعر', 'السعر_معدل']])
```

#### 🔍 الناتج:
```
   المنتج  السعر  السعر_معدل
0    تفاح    3.5     -831.5
1     موز    2.0     -833.0
2   لابتوب 2500.0     1665.0
```

> ✅ مفيد في التحضير للـ ML.

---

### 📌 المثال 4: مع `groupby` — حساب الانحراف عن المتوسط

```python
# انحراف كل منتج عن متوسط فئته
df['الانحراف_عن_المتوسط'] = df.groupby('الفئة')['السعر'].transform(lambda x: x - x.mean())
```

> ✅ يُستخدم في التحليل النسبي.

---

## 🔹 **5. `filter()` — تصفيّة الصفوف أو الأعمدة بمنطق مخصص**

ليس مثل `df[condition]`، بل يُستخدم لتصفية **حسب التسمية أو منطق مخصص**.

### 📌 المثال 5: الاحتفاظ بالأعمدة التي تبدأ بـ "السعر"

```python
price_cols = df.filter(like='السعر')
print(price_cols)
```

#### 🔍 الناتج:
```
   السعر  السعر_النهائي  السعر_دولار  السعر_معدل
0    3.5           5.85     0.933333     -831.5
1    2.0           4.30     0.533333     -833.0
2 2500.0        2860.00   666.666667    1665.0
```

---

### 📌 المثال 6: تصفية الصفوف باستخدام دالة

```python
# الاحتفاظ بالصفوف التي تحتوي على "ل" في اسم المنتج
filtered = df.filter(items=df[df['المنتج'].str.contains('ل')].index, axis=0)
```

> ✅ نادر الاستخدام، لكنه مفيد في السيناريوهات الديناميكية.

---

## 🔹 **الأخطاء الشائعة**

| الخطأ | السبب | الحل |
|------|------|------|
| `apply` بطيء | دالة معقدة أو بيانات كبيرة | استخدم `np.vectorize` أو `@njit` من Numba |
| `pipe` لا يُعيد DataFrame | الدالة لا تُرجع `df` | تأكد من `return df` |
| `transform` يُعطي خطأ | الدالة تُرجع قيمة واحدة بدل قائمة | تأكد أن الناتج نفس طول العمود |
| `filter` لا يُستخدم كـ `df[condition]` | يُستخدم للتصفية بالاسم، ليس بالقيمة | استخدم `loc` للشروط |

---

## 🔹 **تمارين**

1. اكتب دالة `apply` تحسب "مدة الصلاحية" بناءً على تاريخ الإنتاج.
2. أنشئ أنبوب `pipe` ينظف جدول مبيعات.
3. استخدم `transform` لحساب النسبة المئوية لكل قيمة من مجموع عمودها.
4. كيف تُرجع الأعمدة التي تحتوي على "السعر" أو "الإجمالي"؟

---

## 🔹 **الربط بالواقع: أنبوب تحليل مالي**

```python
def add_profit_margin(df):
    df = df.copy()
    df['الهامش'] = (df['السعر'] - df['التكلفة']) / df['السعر']
    return df

def flag_high_margin(df, threshold=0.5):
    df['عالي_الهامش'] = df['الهامش'] > threshold
    return df

report = (df
    .pipe(add_profit_margin)
    .pipe(flag_high_margin, threshold=0.6)
    .assign(الإجمالي=lambda x: x['السعر'] * x['الكمية'])
)

print("📊 تقرير الهوامش:")
print(report[['المنتج', 'الهامش', 'عالي_الهامش']])
```

> ✅ هذا النمط يُستخدم في الأنظمة الآلية.

---

## 🔹 **نصائح احترافية**

- استخدم `apply` للوظائف المعقدة التي لا يمكن تفاديها.
- استخدم `pipe` لتحسين قراءة الكود.
- استخدم `transform` في التحضير للنمذجة.
- تجنب `apply` في الحلقات الكبيرة — فهو بطيء.
- وثّق كل دالة تستخدمها في `pipe`.

---

## 🔹 **أسئلة مراجعة**

1. ما الفرق بين `apply` و `transform`؟
2. متى نستخدم `pipe`؟
3. ما بديل `applymap` في Pandas الحديث؟
4. كيف تُرجع الأعمدة التي تحتوي على كلمة معينة؟
5. ما الفائدة من `transform` مع `groupby`؟

بالطبع! إليك:

---

# 📘 **الدرس 8  : 🎯 مشروع تطبيقي: تحليل بيانات أسهم باستخدام Pandas المتقدم**

> ✅ **عدد الكلمات: ~1700**  
> ✅ **الدرس الأخير في الدليل المتقدم**  
> ✅ **دمج شامل لكل ما تعلمته: من MultiIndex إلى ML Preparation**

---

## 🔹 **مقدمة: لماذا نحلّل بيانات الأسهم؟**

تحليل الأسهم هو أحد أقوى تطبيقات Pandas المتقدمة.  
في هذا المشروع، ستُطبّق كل الأدوات التي تعلمتها:
- البيانات الزمنية
- العمليات الإحصائية
- Pivot Tables
- التحضير للذكاء الاصطناعي
- الأنابيب (Pipelines)
- التصور (مباشرة أو للتصدير)

> 💡 الهدف: بناء **نظام تحليل كمي (Quantitative Analysis)** يُمكنك من:
> - فهم أداء السهم
> - اكتشاف الأنماط
> - إعداد البيانات لنموذج تنبؤ

---

## 🔹 **المرحلة 1: تحميل البيانات وتهيئتها**

### 📌 1.1 توليد بيانات وهمية لسهم (أو استخدام بيانات حقيقية)

```python
import pandas as pd
import numpy as np

# توليد تواريخ عمل (أيام عمل فقط)
dates = pd.bdate_range('2023-01-01', '2023-12-31', freq='B')  # Business days

# توليد سعر باستخدام مشي عشوائي (Random Walk)
np.random.seed(42)
prices = 100 + np.random.randn(len(dates)).cumsum()
volume = np.random.randint(500, 2000, len(dates))

# إنشاء DataFrame
df = pd.DataFrame({
    'السعر': prices,
    'الحجم': volume,
    'الفتح': prices - np.random.rand(len(prices)),
    'الإغلاق': prices,
    'الأعلى': prices + np.random.rand(len(prices)),
    'الأدنى': prices - np.random.rand(len(prices))
}, index=dates)

df.index.name = 'التاريخ'
print(df.head())
```

#### 🔍 الناتج:
```
            السعر   الحجم     الفتح   الإغلاق     الأعلى     الأدنى
التاريخ                                                        
2023-01-02  99.5  1234  98.7    99.5   100.2   98.9
2023-01-03 100.8  1567 100.1   100.8   101.5  100.0
...
```

> ✅ تم إنشاء بيانات شبيهة بالواقع.

---

## 🔹 **المرحلة 2: التحليل الزمني المتقدم**

### 📌 2.1 إعادة عينة إلى أسبوعية

```python
# تحويل البيانات اليومية إلى أسبوعية
weekly = df.resample('W').agg({
    'السعر': 'last',
    'الحجم': 'sum',
    'الأعلى': 'max',
    'الأدنى': 'min'
})
print("📊 البيانات الأسبوعية:")
print(weekly.head())
```

---

### 📌 2.2 المؤشرات الفنية: المتوسطات المتحركة

```python
# المتوسط المتحرك 7 أيام و21 يومًا
df['MA_7'] = df['السعر'].rolling(7).mean()
df['MA_21'] = df['السعر'].rolling(21).mean()

# المتوسط المتحرك المرجح أسيًا
df['EWMA'] = df['السعر'].ewm(span=10).mean()
```

---

### 📌 2.3 التغيرات اليومية والنسبة المئوية

```python
df['التغير'] = df['السعر'].diff()
df['النسبة_المئوية'] = df['السعر'].pct_change() * 100
df['الاتجاه'] = np.where(df['التغير'] > 0, 'صاعد', 'هابط')
```

---

## 🔹 **المرحلة 3: التحليل الإحصائي والهرمي**

### 📌 3.1 MultiIndex: تقسيم السنة إلى أشهر وأسابيع

```python
# إنشاء MultiIndex: السنة، الشهر، الأسبوع
df_reset = df.reset_index()
df_reset['السنة'] = df_reset['التاريخ'].dt.year
df_reset['الشهر'] = df_reset['التاريخ'].dt.month_name()
df_reset['الأسبوع'] = df_reset['التاريخ'].dt.isocalendar().week

# تحويل إلى MultiIndex
df_multi = df_reset.set_index(['السنة', 'الشهر', 'الأسبوع'])
print(df_multi[['السعر', 'الحجم']].head(6))
```

---

### 📌 3.2 Pivot Table: أداء الأشهر

```python
pivot_month = df_reset.pivot_table(
    index='الشهر',
    values='النسبة_المئوية',
    aggfunc=['mean', 'std', 'count'],
    fill_value=0
)
print("📊 أداء شهري:")
print(pivot_month.round(3))
```

---

### 📌 3.3 crosstab: عدد الأيام الصاعدة مقابل الهابطة

```python
cross_direction = pd.crosstab(
    df_reset['الشهر'],
    df_reset['الاتجاه'],
    normalize='index'  # النسبة المئوية لكل شهر
)
print("📈 توزيع الاتجاه الشهري:")
print(cross_direction.round(2))
```

---

## 🔹 **المرحلة 4: التحضير للذكاء الاصطناعي (ML)**

### 📌 4.1 تصنيف السعر إلى فئات

```python
# تقسيم السعر إلى فئات باستخدام qcut
df_reset['فئة_السعر'] = pd.qcut(df_reset['السعر'], q=3, labels=['منخفض', 'متوسط', 'عالي'])

# تحويل الفئة إلى متغيرات وهمية (One-Hot)
df_ml = pd.get_dummies(df_reset, columns=['فئة_السعر'], prefix='سعر')
```

---

### 📌 4.2 استخراج الميزات (Features)

```python
# ميزات زمنية
df_ml['يوم_الأسبوع'] = df_ml['التاريخ'].dt.dayofweek
df_ml['هل_عطلة'] = df_ml['يوم_الأسبوع'].isin([4, 5]).astype(int)  # الجمعة والسبت

# ميزات تقنية
df_ml['MA_ratio'] = df_ml['MA_7'] / df_ml['MA_21']
df_ml['볼_بنك'] = (df_ml['السعر'] - df_ml['الأدنى']) / (df_ml['الأعلى'] - df_ml['الأدنى'] + 1e-8)
```

---

### 📌 4.3 تنظيف وتجهيز النهائي

```python
# حذف الصفوف التي بها NaN (بسبب rolling)
df_ml = df_ml.dropna()

# تحديد الأعمدة النهائية
features = ['MA_7', 'MA_21', 'الحجم', 'النسبة_المئوية', 'MA_ratio', '볼_بنك', 'هل_عطلة']
target = 'فئة_السعر_عالي'  # هل السعر عالي؟

X = df_ml[features]
y = df_ml[target]

print(f"✅ البيانات جاهزة: {X.shape[0]} صفوف، {X.shape[1]} ميزة")
```

---

## 🔹 **المرحلة 5: أنبوب معالجة (Pipeline) باستخدام `pipe`**

```python
def add_technical_indicators(df):
    df = df.copy()
    df['MA_7'] = df['السعر'].rolling(7).mean()
    df['MA_21'] = df['السعر'].rolling(21).mean()
    df['النسبة_المئوية'] = df['السعر'].pct_change()
    return df

def create_target(df):
    df = df.copy()
    df['فئة_السعر'] = pd.qcut(df['السعر'], q=2, labels=[0,1])
    return df

def select_features(df):
    df['يوم_الأسبوع'] = df['التاريخ'].dt.dayofweek
    features = ['MA_7', 'MA_21', 'الحجم', 'النسبة_المئوية', 'يوم_الأسبوع']
    return df[features + ['فئة_السعر']].dropna()

# تنفيذ الأنبوب
ml_ready = (df_reset
    .pipe(add_technical_indicators)
    .pipe(create_target)
    .pipe(select_features)
)

print("🚀 البيانات النهائية للنموذج:")
print(ml_ready.head())
```

---

## 🔹 **الأخطاء الشائعة في المشاريع الحقيقية**

| المشكلة | الحل |
|--------|------|
| `NaN` بعد `rolling` | استخدام `dropna()` أو `fillna()` |
| الفهرس ليس زمنيًا | استخدام `pd.to_datetime()` و `set_index()` |
| Overfitting في التصنيف | تجنب استخدام المستقبل في الميزات |
| تكرار الصفوف | استخدام `drop_duplicates()` |
| بطء الأداء | تجنب `apply` في الحلقات الكبيرة |

---

## 🔹 **تمارين تطبيقية**

1. أضف مؤشر RSI (Relative Strength Index) إلى التحليل.
2. حول التحليل إلى دالة قابلة لإعادة الاستخدام.
3. احفظ النتائج إلى ملف Excel به عدة أوراق.
4. ارسم المتوسطات المتحركة (يمكن استخدام `matplotlib`).

---

## 🔹 **نصائح احترافية**

- استخدم `pipe` لبناء أنابيب قابلة لإعادة الاستخدام.
- وثّق كل خطوة في المشروع.
- احفظ البيانات الوسيطة للتصحيح.
- استخدم `copy()` عند الحاجة لتجنب التحذيرات.
- اختبر الكود على جزء صغير من البيانات أولًا.

---

## 🔹 **الاستخدامات الواقعية**

- 📈 تحليل أداء الأسهم
- 🏪 تحليل مبيعات متعددة الفروع
- 🏥 تحليل بيانات طبية زمنية
- 🌐 تحليل حركة المرور على المواقع

---

## 🔹 **أسئلة مراجعة**

1. كيف تُنشئ مؤشرات فنية في Pandas؟
2. ما دور `qcut` في التصنيف؟
3. كيف تُجهّز البيانات لنموذج ML؟
4. ما فائدة `pipe` في المشاريع الكبيرة؟
5. كيف تتعامل مع `NaN` بعد `rolling`؟

---

> ✅ **نهاية الدرس 8 الموسع — عدد الكلمات: ~1700**

---

# 🎉 **تهانينا! لقد أكملت الدليل المتقدم بالكامل**

> ✅ **إجمالي الكلمات: أكثر من 18,000 كلمة**  
> ✅ **12 درسًا أساسيًا + 8 دروس متقدمة**  
> ✅ **تمارين، أمثلة، مشاريع، وفهرس كامل**

---

# 📎 **الملحقات النهائية**

## ✅ 1. **جدول دوال Pandas المتقدمة (مرجع سريع)**

| الدالة | الوصف |
|--------|------|
| `pd.MultiIndex` | إنشاء فهرس هرمي |
| `stack()`, `unstack()` | تحويل بين الطول والعرض |
| `rolling().mean()` | المتوسط المتحرك |
| `expanding().sum()` | المجموع التراكمي |
| `ewm().mean()` | المتوسط المرجح أسيًا |
| `corr()`, `cov()` | الارتباط والتباين |
| `pivot_table()` | تقرير متقاطع |
| `crosstab()` | جدول تقابل |
| `get_dummies()` | ترميز فئات |
| `cut()`, `qcut()` | تصنيف الأرقام |
| `resample('W')` | إعادة عينة زمنية |
| `shift(1)` | قيمة سابقة (Lag) |
| `diff()` | الفرق بين القيم |
| `.copy(deep=True)` | نسخ آمن |
| `apply()` | تطبيق دالة مخصصة |
| `pipe()` | بناء أنابيب |
| `transform()` | تحويل مع الحفاظ على الشكل |

---

## ✅ 2. **كيفية الاستخدام**

- احفظ هذا الدليل كـ **مصدر تعليمي دائم**
- استخدمه كـ **تدريب داخلي لفريقك**
- حوّله إلى **دورة تدريبية**
- أنشئ عليه **مشاريعك الخاصة**